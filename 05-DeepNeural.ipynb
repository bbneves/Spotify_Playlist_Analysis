{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb5472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10586e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>followers</th>\n",
       "      <th>songs</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>playlist_uri</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>popularity</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>song_name</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>...</td>\n",
       "      <td>4,113,578</td>\n",
       "      <td>52</td>\n",
       "      <td>K-Pop</td>\n",
       "      <td>Pop</td>\n",
       "      <td>spotify:playlist:37i9dQZF1DX9tPFwDMOaN1</td>\n",
       "      <td>spotify:track:0skYUMpS0AcbpjcGsAbRGj</td>\n",
       "      <td>88</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>Pink Venom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>...</td>\n",
       "      <td>295,173</td>\n",
       "      <td>70</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Rock</td>\n",
       "      <td>spotify:playlist:37i9dQZF1DX6tPTxr8qwRe</td>\n",
       "      <td>spotify:track:0skYUMpS0AcbpjcGsAbRGj</td>\n",
       "      <td>87</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>Pink Venom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>...</td>\n",
       "      <td>2,642,529</td>\n",
       "      <td>87</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Indie</td>\n",
       "      <td>spotify:playlist:37i9dQZF1DWUa8ZRTfalHk</td>\n",
       "      <td>spotify:track:0skYUMpS0AcbpjcGsAbRGj</td>\n",
       "      <td>87</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>Pink Venom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>...</td>\n",
       "      <td>762,848</td>\n",
       "      <td>50</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Pop</td>\n",
       "      <td>spotify:playlist:37i9dQZF1DX0kbJZpiYdZl</td>\n",
       "      <td>spotify:track:0skYUMpS0AcbpjcGsAbRGj</td>\n",
       "      <td>87</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>Pink Venom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>...</td>\n",
       "      <td>31,728,611</td>\n",
       "      <td>50</td>\n",
       "      <td>Pop</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>spotify:playlist:37i9dQZF1DXcBWIGoYBM5M</td>\n",
       "      <td>spotify:track:0skYUMpS0AcbpjcGsAbRGj</td>\n",
       "      <td>87</td>\n",
       "      <td>BLACKPINK</td>\n",
       "      <td>Pink Venom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "0           0         0.798   0.697    0    -7.139     1       0.0891   \n",
       "1           1         0.798   0.697    0    -7.139     1       0.0891   \n",
       "2           2         0.798   0.697    0    -7.139     1       0.0891   \n",
       "3           3         0.798   0.697    0    -7.139     1       0.0891   \n",
       "4           4         0.798   0.697    0    -7.139     1       0.0891   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  ...   followers  songs genre_1  \\\n",
       "0        0.0202               0.0     0.259  ...   4,113,578     52   K-Pop   \n",
       "1        0.0202               0.0     0.259  ...     295,173     70     Pop   \n",
       "2        0.0202               0.0     0.259  ...   2,642,529     87     Pop   \n",
       "3        0.0202               0.0     0.259  ...     762,848     50     Pop   \n",
       "4        0.0202               0.0     0.259  ...  31,728,611     50     Pop   \n",
       "\n",
       "  genre_2                             playlist_uri  \\\n",
       "0     Pop  spotify:playlist:37i9dQZF1DX9tPFwDMOaN1   \n",
       "1    Rock  spotify:playlist:37i9dQZF1DX6tPTxr8qwRe   \n",
       "2   Indie  spotify:playlist:37i9dQZF1DWUa8ZRTfalHk   \n",
       "3     Pop  spotify:playlist:37i9dQZF1DX0kbJZpiYdZl   \n",
       "4     R&B  spotify:playlist:37i9dQZF1DXcBWIGoYBM5M   \n",
       "\n",
       "                              track_uri popularity  artist_name   song_name  \\\n",
       "0  spotify:track:0skYUMpS0AcbpjcGsAbRGj         88    BLACKPINK  Pink Venom   \n",
       "1  spotify:track:0skYUMpS0AcbpjcGsAbRGj         87    BLACKPINK  Pink Venom   \n",
       "2  spotify:track:0skYUMpS0AcbpjcGsAbRGj         87    BLACKPINK  Pink Venom   \n",
       "3  spotify:track:0skYUMpS0AcbpjcGsAbRGj         87    BLACKPINK  Pink Venom   \n",
       "4  spotify:track:0skYUMpS0AcbpjcGsAbRGj         87    BLACKPINK  Pink Venom   \n",
       "\n",
       "  popular  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the CSV file with all the information merged together\n",
    "ml_df = pd.read_csv('Resources/all_data.csv', index_col=False)\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d10b5d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06450    122\n",
       "0.89100     83\n",
       "0.18400     81\n",
       "0.65900     69\n",
       "0.05750     67\n",
       "          ... \n",
       "0.00256      1\n",
       "0.07510      1\n",
       "0.00286      1\n",
       "0.00632      1\n",
       "0.00376      1\n",
       "Name: acousticness, Length: 2599, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ml_df.count()\n",
    "ml_df['acousticness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c399be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>K-Pop</td>\n",
       "      <td>Pop</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Rock</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Indie</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Pop</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "0         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "1         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "2         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "3         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "4         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "\n",
       "   instrumentalness  liveness  valence   tempo  duration_ms genre_1 genre_2  \\\n",
       "0               0.0     0.259    0.745  90.031       186964   K-Pop     Pop   \n",
       "1               0.0     0.259    0.745  90.031       186964     Pop    Rock   \n",
       "2               0.0     0.259    0.745  90.031       186964     Pop   Indie   \n",
       "3               0.0     0.259    0.745  90.031       186964     Pop     Pop   \n",
       "4               0.0     0.259    0.745  90.031       186964     Pop     R&B   \n",
       "\n",
       "   popularity  popular  \n",
       "0          88        1  \n",
       "1          87        1  \n",
       "2          87        1  \n",
       "3          87        1  \n",
       "4          87        1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping columns which is specific for each song (like name and uri)\n",
    "ml_df = ml_df.drop(columns=['Unnamed: 0', 'followers', 'songs',\n",
    "                            'playlist_uri','track_uri','artist_name',\n",
    "                            'song_name', 'analysis_url', 'id','uri',\n",
    "                            'time_signature', 'playlist_name','track_href',\n",
    "                            'type', 'mode' ])\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4420c19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre_1    17\n",
       "genre_2    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determining the number of unique values in each column.\n",
    "cat_ml = ml_df.dtypes[ml_df.dtypes == 'object'].index.tolist()\n",
    "\n",
    "ml_df[cat_ml].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "724db704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop                  2707\n",
       "Rock                 1350\n",
       "Indie                1295\n",
       "Latin                1151\n",
       "Electronic            847\n",
       "Rap                   792\n",
       "Jazz                  544\n",
       "R&B                   528\n",
       "Blues                 523\n",
       "Instrumental          522\n",
       "Country               503\n",
       "Singer-Songwriter     493\n",
       "Metal                 434\n",
       "Christian             243\n",
       "Alternative           167\n",
       "K-Pop                 161\n",
       "Classical             159\n",
       "Name: genre_1, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_type_count = ml_df.genre_1.value_counts()\n",
    "genre_type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8098fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "genre_type_count.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6396de5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other         4277\n",
       "Pop           2707\n",
       "Rock          1350\n",
       "Indie         1295\n",
       "Latin         1151\n",
       "Electronic     847\n",
       "Rap            792\n",
       "Name: genre_1, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting which values to replace\n",
    "replace_genre = list(genre_type_count[genre_type_count < 550].index)\n",
    "\n",
    "for song in replace_genre:\n",
    "    ml_df.genre_1 = ml_df.genre_1.replace(song,'Other')\n",
    "    \n",
    "ml_df.genre_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "629fd112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop                   3287\n",
       "Indie                 1569\n",
       "Rock                  1123\n",
       "Alternative           1023\n",
       "Workout               1020\n",
       "Electronic             924\n",
       "Ambient                522\n",
       "Roots                  519\n",
       "Rap                    409\n",
       "Instrumental           339\n",
       "Funk                   320\n",
       "Gospel                 243\n",
       "R&B                    221\n",
       "Gaming                 155\n",
       "Adult Contemporary     145\n",
       "K-Pop                  144\n",
       "Reggaeton              132\n",
       "Country                120\n",
       "Acoustic               103\n",
       "Metal                  101\n",
       "Name: genre_2, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2_type_count = ml_df.genre_2.value_counts()\n",
    "g2_type_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbbb6f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g2_type_count.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1cde06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other          3473\n",
       "Pop            3287\n",
       "Indie          1569\n",
       "Rock           1123\n",
       "Alternative    1023\n",
       "Workout        1020\n",
       "Electronic      924\n",
       "Name: genre_2, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting which values to replace\n",
    "replace_genre2 = list(g2_type_count[g2_type_count < 550].index)\n",
    "\n",
    "for song in replace_genre2:\n",
    "    ml_df.genre_2 = ml_df.genre_2.replace(song,'Other')\n",
    "    \n",
    "ml_df.genre_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "862f8c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Other</td>\n",
       "      <td>Pop</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Rock</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Indie</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Pop</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Other</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "0         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "1         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "2         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "3         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "4         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "\n",
       "   instrumentalness  liveness  valence   tempo  duration_ms genre_1 genre_2  \\\n",
       "0               0.0     0.259    0.745  90.031       186964   Other     Pop   \n",
       "1               0.0     0.259    0.745  90.031       186964     Pop    Rock   \n",
       "2               0.0     0.259    0.745  90.031       186964     Pop   Indie   \n",
       "3               0.0     0.259    0.745  90.031       186964     Pop     Pop   \n",
       "4               0.0     0.259    0.745  90.031       186964     Pop   Other   \n",
       "\n",
       "   popularity  popular  \n",
       "0          88        1  \n",
       "1          87        1  \n",
       "2          87        1  \n",
       "3          87        1  \n",
       "4          87        1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_ml_df = ml_df.copy()\n",
    "save_ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "327c07f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   genre_1_Electronic  genre_1_Indie  genre_1_Latin  genre_1_Other  \\\n",
      "0                 0.0            0.0            0.0            1.0   \n",
      "1                 0.0            0.0            0.0            0.0   \n",
      "2                 0.0            0.0            0.0            0.0   \n",
      "3                 0.0            0.0            0.0            0.0   \n",
      "4                 0.0            0.0            0.0            0.0   \n",
      "\n",
      "   genre_1_Pop  genre_1_Rap  genre_1_Rock  \n",
      "0          0.0          0.0           0.0  \n",
      "1          1.0          0.0           0.0  \n",
      "2          1.0          0.0           0.0  \n",
      "3          1.0          0.0           0.0  \n",
      "4          1.0          0.0           0.0  \n",
      "   genre_2_Alternative  genre_2_Electronic  genre_2_Indie  genre_2_Other  \\\n",
      "0                  0.0                 0.0            0.0            0.0   \n",
      "1                  0.0                 0.0            0.0            0.0   \n",
      "2                  0.0                 0.0            1.0            0.0   \n",
      "3                  0.0                 0.0            0.0            0.0   \n",
      "4                  0.0                 0.0            0.0            1.0   \n",
      "\n",
      "   genre_2_Pop  genre_2_Rock  genre_2_Workout  \n",
      "0          1.0           0.0              0.0  \n",
      "1          0.0           1.0              0.0  \n",
      "2          0.0           0.0              0.0  \n",
      "3          1.0           0.0              0.0  \n",
      "4          0.0           0.0              0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bneves/opt/anaconda3/envs/mlenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/bneves/opt/anaconda3/envs/mlenv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Transposing the genre variability (trying with both genres first, than with only genre2)\n",
    "# OneHoteEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit the encoder and produce an encoded DF\n",
    "\n",
    "encode_df = pd.DataFrame(enc.fit_transform(ml_df.genre_1.values.reshape(-1,1)))\n",
    "encode_df.columns = enc.get_feature_names(['genre_1'])\n",
    "\n",
    "encode2_df = pd.DataFrame(enc.fit_transform(ml_df.genre_2.values.reshape(-1,1)))\n",
    "encode2_df.columns = enc.get_feature_names(['genre_2'])\n",
    "\n",
    "print(encode_df.head())\n",
    "print(encode2_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a38c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = genre1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24e7b4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Other</td>\n",
       "      <td>Pop</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Rock</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Indie</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Pop</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Other</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "0         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "1         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "2         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "3         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "4         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "\n",
       "   instrumentalness  liveness  valence   tempo  duration_ms genre_1 genre_2  \\\n",
       "0               0.0     0.259    0.745  90.031       186964   Other     Pop   \n",
       "1               0.0     0.259    0.745  90.031       186964     Pop    Rock   \n",
       "2               0.0     0.259    0.745  90.031       186964     Pop   Indie   \n",
       "3               0.0     0.259    0.745  90.031       186964     Pop     Pop   \n",
       "4               0.0     0.259    0.745  90.031       186964     Pop   Other   \n",
       "\n",
       "   popularity  popular  \n",
       "0          88        1  \n",
       "1          87        1  \n",
       "2          87        1  \n",
       "3          87        1  \n",
       "4          87        1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_ml_df = ml_df.copy()\n",
    "save_ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9946b9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Other</td>\n",
       "      <td>Pop</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Rock</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Indie</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Pop</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Other</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "0         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "1         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "2         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "3         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "4         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "\n",
       "   instrumentalness  liveness  valence   tempo  duration_ms genre_1 genre_2  \\\n",
       "0               0.0     0.259    0.745  90.031       186964   Other     Pop   \n",
       "1               0.0     0.259    0.745  90.031       186964     Pop    Rock   \n",
       "2               0.0     0.259    0.745  90.031       186964     Pop   Indie   \n",
       "3               0.0     0.259    0.745  90.031       186964     Pop     Pop   \n",
       "4               0.0     0.259    0.745  90.031       186964     Pop   Other   \n",
       "\n",
       "   popularity  popular  \n",
       "0          88        1  \n",
       "1          87        1  \n",
       "2          87        1  \n",
       "3          87        1  \n",
       "4          87        1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = save_ml_df.copy()\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "faf897da",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability          12419\n",
       "energy                12419\n",
       "key                   12419\n",
       "loudness              12419\n",
       "speechiness           12419\n",
       "acousticness          12419\n",
       "instrumentalness      12419\n",
       "liveness              12419\n",
       "valence               12419\n",
       "tempo                 12419\n",
       "duration_ms           12419\n",
       "popularity            12419\n",
       "popular               12419\n",
       "genre_1_Electronic    12419\n",
       "genre_1_Indie         12419\n",
       "genre_1_Latin         12419\n",
       "genre_1_Other         12419\n",
       "genre_1_Pop           12419\n",
       "genre_1_Rap           12419\n",
       "genre_1_Rock          12419\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MErging genre1 then genre2 and drop originals in the process\n",
    "\n",
    "ml_df = ml_df.merge(encode_df,left_index=True, right_index=True)\n",
    "#ml_df = ml_df.merge(encode2_df, left_index=True, right_index=True)\n",
    "\n",
    "ml_df = ml_df.drop(columns=genres)\n",
    "\n",
    "ml_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bae090",
   "metadata": {},
   "source": [
    "### Here we are splitting the strategy into two possibilities:\n",
    "1 - We will use the popular column (0 or 1) as the target. Criteria for 1 is: popularity > 60\n",
    "\n",
    "2 - Use the popularity scores as target and try to predict a reasonable score comparing to the original spotify score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "704e551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popular</th>\n",
       "      <th>genre_1_Electronic</th>\n",
       "      <th>genre_1_Indie</th>\n",
       "      <th>genre_1_Latin</th>\n",
       "      <th>genre_1_Other</th>\n",
       "      <th>genre_1_Pop</th>\n",
       "      <th>genre_1_Rap</th>\n",
       "      <th>genre_1_Rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12414</th>\n",
       "      <td>0.582</td>\n",
       "      <td>0.730</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.678</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.240</td>\n",
       "      <td>129.981</td>\n",
       "      <td>201668</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12415</th>\n",
       "      <td>0.582</td>\n",
       "      <td>0.730</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.678</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.240</td>\n",
       "      <td>129.981</td>\n",
       "      <td>201668</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12416</th>\n",
       "      <td>0.481</td>\n",
       "      <td>0.917</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.366</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.3980</td>\n",
       "      <td>0.377</td>\n",
       "      <td>108.747</td>\n",
       "      <td>185317</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12417</th>\n",
       "      <td>0.628</td>\n",
       "      <td>0.787</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.540</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.00376</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.611</td>\n",
       "      <td>137.981</td>\n",
       "      <td>179947</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12418</th>\n",
       "      <td>0.384</td>\n",
       "      <td>0.623</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.022</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.458</td>\n",
       "      <td>77.067</td>\n",
       "      <td>310840</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "12414         0.582   0.730   11    -7.678       0.0402       0.26000   \n",
       "12415         0.582   0.730   11    -7.678       0.0402       0.26000   \n",
       "12416         0.481   0.917    2    -3.366       0.0385       0.00104   \n",
       "12417         0.628   0.787    4    -6.540       0.0328       0.00376   \n",
       "12418         0.384   0.623    2    -8.022       0.0282       0.10400   \n",
       "\n",
       "       instrumentalness  liveness  valence    tempo  duration_ms  popularity  \\\n",
       "12414          0.000004    0.1100    0.240  129.981       201668          57   \n",
       "12415          0.000004    0.1100    0.240  129.981       201668          57   \n",
       "12416          0.000004    0.3980    0.377  108.747       185317          44   \n",
       "12417          0.027200    0.0872    0.611  137.981       179947          44   \n",
       "12418          0.207000    0.1270    0.458   77.067       310840          55   \n",
       "\n",
       "       popular  genre_1_Electronic  genre_1_Indie  genre_1_Latin  \\\n",
       "12414        0                 0.0            0.0            0.0   \n",
       "12415        0                 0.0            1.0            0.0   \n",
       "12416        0                 0.0            0.0            0.0   \n",
       "12417        0                 0.0            0.0            0.0   \n",
       "12418        0                 0.0            0.0            0.0   \n",
       "\n",
       "       genre_1_Other  genre_1_Pop  genre_1_Rap  genre_1_Rock  \n",
       "12414            1.0          0.0          0.0           0.0  \n",
       "12415            0.0          0.0          0.0           0.0  \n",
       "12416            1.0          0.0          0.0           0.0  \n",
       "12417            1.0          0.0          0.0           0.0  \n",
       "12418            1.0          0.0          0.0           0.0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save2_ml_df = ml_df.copy()\n",
    "save2_ml_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "686cd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the preprocessed data into features and targets\n",
    "\n",
    "X = ml_df.drop(columns=['popular', 'popularity'])\n",
    "y = ml_df['popular'].values\n",
    "\n",
    "# Training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) # Test size is 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "164ab9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ff4d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9314\n",
      "3105\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_scaled))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100fd81f",
   "metadata": {},
   "source": [
    "## Done prep. Now it is Play time with neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3abbf9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae8f0779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 28)                532       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 953\n",
      "Trainable params: 953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 14:46:18.198851: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-09-07 14:46:18.203000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# Adopting 42 neurons which is something between 2 to 3 times the number of features\n",
    "\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 28\n",
    "hidden_nodes_layer2 = 14\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the strucutre of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d387fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f0ca150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a checkpoint save\n",
    "\n",
    "os.makedirs(\"checkpoints/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06852dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights every epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be68b2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 14:53:23.311732: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.6272 - accuracy: 0.6442\n",
      "Epoch 2/100\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.5138 - accuracy: 0.7370\n",
      "Epoch 3/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4999 - accuracy: 0.7567\n",
      "Epoch 4/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4855 - accuracy: 0.7632\n",
      "Epoch 5/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.4706 - accuracy: 0.7733\n",
      "Epoch 6/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.4745 - accuracy: 0.7681\n",
      "Epoch 7/100\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.4722 - accuracy: 0.7730\n",
      "Epoch 8/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4590 - accuracy: 0.7821\n",
      "Epoch 9/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.4709 - accuracy: 0.7681\n",
      "Epoch 10/100\n",
      "292/292 [==============================] - 0s 421us/step - loss: 0.4587 - accuracy: 0.7833\n",
      "\n",
      "Epoch 00010: saving model to checkpoints/weights.10.hdf5\n",
      "Epoch 11/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4564 - accuracy: 0.7816\n",
      "Epoch 12/100\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.4539 - accuracy: 0.7835\n",
      "Epoch 13/100\n",
      "292/292 [==============================] - 0s 421us/step - loss: 0.4493 - accuracy: 0.7819\n",
      "Epoch 14/100\n",
      "292/292 [==============================] - 0s 423us/step - loss: 0.4519 - accuracy: 0.7858\n",
      "Epoch 15/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.4367 - accuracy: 0.7983\n",
      "Epoch 16/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.4409 - accuracy: 0.7930\n",
      "Epoch 17/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4368 - accuracy: 0.7946\n",
      "Epoch 18/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4365 - accuracy: 0.7944\n",
      "Epoch 19/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.4360 - accuracy: 0.7891\n",
      "Epoch 20/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.4398 - accuracy: 0.8010\n",
      "\n",
      "Epoch 00020: saving model to checkpoints/weights.20.hdf5\n",
      "Epoch 21/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.4365 - accuracy: 0.7937\n",
      "Epoch 22/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.4175 - accuracy: 0.8043\n",
      "Epoch 23/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.4277 - accuracy: 0.8015\n",
      "Epoch 24/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4247 - accuracy: 0.7996\n",
      "Epoch 25/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.4234 - accuracy: 0.8002\n",
      "Epoch 26/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.4269 - accuracy: 0.7982\n",
      "Epoch 27/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.4286 - accuracy: 0.7988\n",
      "Epoch 28/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4189 - accuracy: 0.8023\n",
      "Epoch 29/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.4303 - accuracy: 0.8014\n",
      "Epoch 30/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.4223 - accuracy: 0.7975\n",
      "\n",
      "Epoch 00030: saving model to checkpoints/weights.30.hdf5\n",
      "Epoch 31/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.4155 - accuracy: 0.8078\n",
      "Epoch 32/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4180 - accuracy: 0.8081\n",
      "Epoch 33/100\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.4252 - accuracy: 0.8034\n",
      "Epoch 34/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.4104 - accuracy: 0.8108\n",
      "Epoch 35/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.4169 - accuracy: 0.8083\n",
      "Epoch 36/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4060 - accuracy: 0.8131\n",
      "Epoch 37/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.4031 - accuracy: 0.8127\n",
      "Epoch 38/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4099 - accuracy: 0.8104\n",
      "Epoch 39/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4103 - accuracy: 0.8105\n",
      "Epoch 40/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.4050 - accuracy: 0.8056\n",
      "\n",
      "Epoch 00040: saving model to checkpoints/weights.40.hdf5\n",
      "Epoch 41/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.4094 - accuracy: 0.8141\n",
      "Epoch 42/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3985 - accuracy: 0.8185\n",
      "Epoch 43/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.4049 - accuracy: 0.8112\n",
      "Epoch 44/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3989 - accuracy: 0.8190\n",
      "Epoch 45/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3888 - accuracy: 0.8232\n",
      "Epoch 46/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.3969 - accuracy: 0.8241\n",
      "Epoch 47/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3931 - accuracy: 0.8249\n",
      "Epoch 48/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3992 - accuracy: 0.8128\n",
      "Epoch 49/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3874 - accuracy: 0.8280\n",
      "Epoch 50/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3943 - accuracy: 0.8228\n",
      "\n",
      "Epoch 00050: saving model to checkpoints/weights.50.hdf5\n",
      "Epoch 51/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3944 - accuracy: 0.8242\n",
      "Epoch 52/100\n",
      "292/292 [==============================] - 0s 434us/step - loss: 0.3913 - accuracy: 0.8256\n",
      "Epoch 53/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3891 - accuracy: 0.8258\n",
      "Epoch 54/100\n",
      "292/292 [==============================] - 0s 418us/step - loss: 0.3807 - accuracy: 0.8319\n",
      "Epoch 55/100\n",
      "292/292 [==============================] - 0s 431us/step - loss: 0.3909 - accuracy: 0.8243\n",
      "Epoch 56/100\n",
      "292/292 [==============================] - 0s 427us/step - loss: 0.3940 - accuracy: 0.8201\n",
      "Epoch 57/100\n",
      "292/292 [==============================] - 0s 425us/step - loss: 0.3798 - accuracy: 0.8252\n",
      "Epoch 58/100\n",
      "292/292 [==============================] - 0s 437us/step - loss: 0.3831 - accuracy: 0.8283\n",
      "Epoch 59/100\n",
      "292/292 [==============================] - 0s 430us/step - loss: 0.3974 - accuracy: 0.8201\n",
      "Epoch 60/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3879 - accuracy: 0.8255\n",
      "\n",
      "Epoch 00060: saving model to checkpoints/weights.60.hdf5\n",
      "Epoch 61/100\n",
      "292/292 [==============================] - 0s 424us/step - loss: 0.3998 - accuracy: 0.8213\n",
      "Epoch 62/100\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.3811 - accuracy: 0.8276\n",
      "Epoch 63/100\n",
      "292/292 [==============================] - 0s 416us/step - loss: 0.3767 - accuracy: 0.8336\n",
      "Epoch 64/100\n",
      "292/292 [==============================] - 0s 422us/step - loss: 0.3750 - accuracy: 0.8338\n",
      "Epoch 65/100\n",
      "292/292 [==============================] - 0s 418us/step - loss: 0.3845 - accuracy: 0.8292\n",
      "Epoch 66/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3857 - accuracy: 0.8253\n",
      "Epoch 67/100\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.3880 - accuracy: 0.8268\n",
      "Epoch 68/100\n",
      "292/292 [==============================] - 0s 422us/step - loss: 0.3788 - accuracy: 0.8205\n",
      "Epoch 69/100\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.3871 - accuracy: 0.8273\n",
      "Epoch 70/100\n",
      "292/292 [==============================] - 0s 422us/step - loss: 0.3839 - accuracy: 0.8310\n",
      "\n",
      "Epoch 00070: saving model to checkpoints/weights.70.hdf5\n",
      "Epoch 71/100\n",
      "292/292 [==============================] - 0s 419us/step - loss: 0.3759 - accuracy: 0.8339\n",
      "Epoch 72/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3793 - accuracy: 0.8292\n",
      "Epoch 73/100\n",
      "292/292 [==============================] - 0s 418us/step - loss: 0.3814 - accuracy: 0.8298\n",
      "Epoch 74/100\n",
      "292/292 [==============================] - 0s 419us/step - loss: 0.3802 - accuracy: 0.8274\n",
      "Epoch 75/100\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.3764 - accuracy: 0.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3744 - accuracy: 0.8285\n",
      "Epoch 77/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3748 - accuracy: 0.8336\n",
      "Epoch 78/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3799 - accuracy: 0.8300\n",
      "Epoch 79/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3790 - accuracy: 0.8326\n",
      "Epoch 80/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3709 - accuracy: 0.8312\n",
      "\n",
      "Epoch 00080: saving model to checkpoints/weights.80.hdf5\n",
      "Epoch 81/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3706 - accuracy: 0.8323\n",
      "Epoch 82/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3750 - accuracy: 0.8328\n",
      "Epoch 83/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3907 - accuracy: 0.8199\n",
      "Epoch 84/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3805 - accuracy: 0.8311\n",
      "Epoch 85/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3668 - accuracy: 0.8351\n",
      "Epoch 86/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3736 - accuracy: 0.8331\n",
      "Epoch 87/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3693 - accuracy: 0.8316\n",
      "Epoch 88/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3689 - accuracy: 0.8337\n",
      "Epoch 89/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3635 - accuracy: 0.8412\n",
      "Epoch 90/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3700 - accuracy: 0.8338\n",
      "\n",
      "Epoch 00090: saving model to checkpoints/weights.90.hdf5\n",
      "Epoch 91/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3637 - accuracy: 0.8391\n",
      "Epoch 92/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3693 - accuracy: 0.8382\n",
      "Epoch 93/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3685 - accuracy: 0.8342\n",
      "Epoch 94/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3560 - accuracy: 0.8412\n",
      "Epoch 95/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3663 - accuracy: 0.8382\n",
      "Epoch 96/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3696 - accuracy: 0.8323\n",
      "Epoch 97/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3596 - accuracy: 0.8423\n",
      "Epoch 98/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3767 - accuracy: 0.8263\n",
      "Epoch 99/100\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.3570 - accuracy: 0.8390\n",
      "Epoch 100/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3671 - accuracy: 0.8314\n",
      "\n",
      "Epoch 00100: saving model to checkpoints/weights.100.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65a46547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 - 0s - loss: 0.4559 - accuracy: 0.7955\n",
      "Loss: 0.4559101164340973, Accuracy: 0.7954911589622498\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model with our test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b91fb386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"relu28_relu14_sigmoid_a79.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ef104",
   "metadata": {},
   "source": [
    "#### Attempting SparseCrossEntropy\n",
    "The reason been that it mathces our dataset:\n",
    " - It is usefull for multiple labels (in our case, 2)\n",
    " - Works well with OneHot (our case as well)\n",
    " \n",
    " (Update: The SparseXE got into a categorical section, which will not work in this setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c5ea930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 28)                532       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 953\n",
      "Trainable params: 953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# Adopting 42 neurons which is something between 2 to 3 times the number of features\n",
    "\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 28\n",
    "hidden_nodes_layer2 = 14\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='sigmoid'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the strucutre of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ba2876e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c532f5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "292/292 [==============================] - 0s 428us/step - loss: 0.6132 - accuracy: 0.6629\n",
      "Epoch 2/100\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.5284 - accuracy: 0.7360\n",
      "Epoch 3/100\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.5103 - accuracy: 0.7395\n",
      "Epoch 4/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.5036 - accuracy: 0.7485\n",
      "Epoch 5/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4928 - accuracy: 0.7546\n",
      "Epoch 6/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.4918 - accuracy: 0.7577\n",
      "Epoch 7/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4954 - accuracy: 0.7581\n",
      "Epoch 8/100\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.4923 - accuracy: 0.7584\n",
      "Epoch 9/100\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.4903 - accuracy: 0.7679\n",
      "\n",
      "Epoch 00009: saving model to checkpoints/weights.09.hdf5\n",
      "Epoch 10/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.4755 - accuracy: 0.7676\n",
      "Epoch 11/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4877 - accuracy: 0.7641\n",
      "Epoch 12/100\n",
      "292/292 [==============================] - 0s 421us/step - loss: 0.4835 - accuracy: 0.7736\n",
      "Epoch 13/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.4872 - accuracy: 0.7681\n",
      "Epoch 14/100\n",
      "292/292 [==============================] - 0s 432us/step - loss: 0.4670 - accuracy: 0.7831\n",
      "Epoch 15/100\n",
      "292/292 [==============================] - 0s 584us/step - loss: 0.4787 - accuracy: 0.7698\n",
      "Epoch 16/100\n",
      "292/292 [==============================] - 0s 477us/step - loss: 0.4817 - accuracy: 0.7679\n",
      "Epoch 17/100\n",
      "292/292 [==============================] - 0s 445us/step - loss: 0.4688 - accuracy: 0.7743\n",
      "Epoch 18/100\n",
      "292/292 [==============================] - 0s 418us/step - loss: 0.4649 - accuracy: 0.7823\n",
      "Epoch 19/100\n",
      "292/292 [==============================] - 0s 416us/step - loss: 0.4626 - accuracy: 0.7807\n",
      "\n",
      "Epoch 00019: saving model to checkpoints/weights.19.hdf5\n",
      "Epoch 20/100\n",
      "292/292 [==============================] - 0s 464us/step - loss: 0.4715 - accuracy: 0.7762\n",
      "Epoch 21/100\n",
      "292/292 [==============================] - 0s 426us/step - loss: 0.4623 - accuracy: 0.7789\n",
      "Epoch 22/100\n",
      "292/292 [==============================] - 0s 425us/step - loss: 0.4643 - accuracy: 0.7806\n",
      "Epoch 23/100\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.4624 - accuracy: 0.7835\n",
      "Epoch 24/100\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.4593 - accuracy: 0.7817\n",
      "Epoch 25/100\n",
      "292/292 [==============================] - 0s 440us/step - loss: 0.4656 - accuracy: 0.7775\n",
      "Epoch 26/100\n",
      "292/292 [==============================] - 0s 483us/step - loss: 0.4605 - accuracy: 0.7807\n",
      "Epoch 27/100\n",
      "292/292 [==============================] - 0s 482us/step - loss: 0.4678 - accuracy: 0.7806\n",
      "Epoch 28/100\n",
      "292/292 [==============================] - 0s 431us/step - loss: 0.4615 - accuracy: 0.7824\n",
      "Epoch 29/100\n",
      "292/292 [==============================] - 0s 426us/step - loss: 0.4635 - accuracy: 0.7826\n",
      "\n",
      "Epoch 00029: saving model to checkpoints/weights.29.hdf5\n",
      "Epoch 30/100\n",
      "292/292 [==============================] - 0s 419us/step - loss: 0.4539 - accuracy: 0.7836\n",
      "Epoch 31/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.4645 - accuracy: 0.7735\n",
      "Epoch 32/100\n",
      "292/292 [==============================] - 0s 451us/step - loss: 0.4586 - accuracy: 0.7804\n",
      "Epoch 33/100\n",
      "292/292 [==============================] - 0s 430us/step - loss: 0.4583 - accuracy: 0.7805\n",
      "Epoch 34/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.4559 - accuracy: 0.7846\n",
      "Epoch 35/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.4552 - accuracy: 0.7896\n",
      "Epoch 36/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.4645 - accuracy: 0.7758\n",
      "Epoch 37/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4524 - accuracy: 0.7897\n",
      "Epoch 38/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.4596 - accuracy: 0.7822\n",
      "Epoch 39/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.4544 - accuracy: 0.7832\n",
      "\n",
      "Epoch 00039: saving model to checkpoints/weights.39.hdf5\n",
      "Epoch 40/100\n",
      "292/292 [==============================] - 0s 435us/step - loss: 0.4563 - accuracy: 0.7858\n",
      "Epoch 41/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.4530 - accuracy: 0.7868\n",
      "Epoch 42/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4446 - accuracy: 0.7894\n",
      "Epoch 43/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4422 - accuracy: 0.7935\n",
      "Epoch 44/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4478 - accuracy: 0.7914\n",
      "Epoch 45/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.4509 - accuracy: 0.7837\n",
      "Epoch 46/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.4580 - accuracy: 0.7873\n",
      "Epoch 47/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4441 - accuracy: 0.7907\n",
      "Epoch 48/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4457 - accuracy: 0.7905\n",
      "Epoch 49/100\n",
      "292/292 [==============================] - 0s 437us/step - loss: 0.4421 - accuracy: 0.7958\n",
      "\n",
      "Epoch 00049: saving model to checkpoints/weights.49.hdf5\n",
      "Epoch 50/100\n",
      "292/292 [==============================] - 0s 434us/step - loss: 0.4456 - accuracy: 0.7911\n",
      "Epoch 51/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.4412 - accuracy: 0.7911\n",
      "Epoch 52/100\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.4307 - accuracy: 0.8040\n",
      "Epoch 53/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.4466 - accuracy: 0.7873\n",
      "Epoch 54/100\n",
      "292/292 [==============================] - 0s 416us/step - loss: 0.4395 - accuracy: 0.7953\n",
      "Epoch 55/100\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.4559 - accuracy: 0.7843\n",
      "Epoch 56/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.4411 - accuracy: 0.7946\n",
      "Epoch 57/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.4431 - accuracy: 0.7939\n",
      "Epoch 58/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.4508 - accuracy: 0.7880\n",
      "Epoch 59/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.4378 - accuracy: 0.7980\n",
      "\n",
      "Epoch 00059: saving model to checkpoints/weights.59.hdf5\n",
      "Epoch 60/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.4361 - accuracy: 0.7921\n",
      "Epoch 61/100\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.4370 - accuracy: 0.7946\n",
      "Epoch 62/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.4389 - accuracy: 0.7946\n",
      "Epoch 63/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.4258 - accuracy: 0.8032\n",
      "Epoch 64/100\n",
      "292/292 [==============================] - 0s 429us/step - loss: 0.4304 - accuracy: 0.7952\n",
      "Epoch 65/100\n",
      "292/292 [==============================] - 0s 466us/step - loss: 0.4310 - accuracy: 0.8042\n",
      "Epoch 66/100\n",
      "292/292 [==============================] - 0s 435us/step - loss: 0.4280 - accuracy: 0.8024\n",
      "Epoch 67/100\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.4429 - accuracy: 0.7899\n",
      "Epoch 68/100\n",
      "292/292 [==============================] - 0s 416us/step - loss: 0.4265 - accuracy: 0.7993\n",
      "Epoch 69/100\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.4300 - accuracy: 0.8002\n",
      "\n",
      "Epoch 00069: saving model to checkpoints/weights.69.hdf5\n",
      "Epoch 70/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.4226 - accuracy: 0.8049\n",
      "Epoch 71/100\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.4330 - accuracy: 0.7968\n",
      "Epoch 72/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.4311 - accuracy: 0.7996\n",
      "Epoch 73/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.4213 - accuracy: 0.8038\n",
      "Epoch 74/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.4243 - accuracy: 0.8021\n",
      "Epoch 75/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.4244 - accuracy: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.4379 - accuracy: 0.7912\n",
      "Epoch 77/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4322 - accuracy: 0.7983\n",
      "Epoch 78/100\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.4243 - accuracy: 0.7996\n",
      "Epoch 79/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.4205 - accuracy: 0.8023\n",
      "\n",
      "Epoch 00079: saving model to checkpoints/weights.79.hdf5\n",
      "Epoch 80/100\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.4277 - accuracy: 0.8003\n",
      "Epoch 81/100\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.4235 - accuracy: 0.8032\n",
      "Epoch 82/100\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.4281 - accuracy: 0.7977\n",
      "Epoch 83/100\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.4242 - accuracy: 0.7969\n",
      "Epoch 84/100\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.4185 - accuracy: 0.8064\n",
      "Epoch 85/100\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.4261 - accuracy: 0.8007\n",
      "Epoch 86/100\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.4214 - accuracy: 0.8034\n",
      "Epoch 87/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4306 - accuracy: 0.7911\n",
      "Epoch 88/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.4207 - accuracy: 0.8011\n",
      "Epoch 89/100\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.4284 - accuracy: 0.8019\n",
      "\n",
      "Epoch 00089: saving model to checkpoints/weights.89.hdf5\n",
      "Epoch 90/100\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.4165 - accuracy: 0.8033\n",
      "Epoch 91/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.4195 - accuracy: 0.8007\n",
      "Epoch 92/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4253 - accuracy: 0.8019\n",
      "Epoch 93/100\n",
      "292/292 [==============================] - 0s 425us/step - loss: 0.4158 - accuracy: 0.8049\n",
      "Epoch 94/100\n",
      "292/292 [==============================] - 0s 436us/step - loss: 0.4165 - accuracy: 0.8077\n",
      "Epoch 95/100\n",
      "292/292 [==============================] - 0s 425us/step - loss: 0.4274 - accuracy: 0.8022\n",
      "Epoch 96/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4161 - accuracy: 0.8032\n",
      "Epoch 97/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4088 - accuracy: 0.8045\n",
      "Epoch 98/100\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.4095 - accuracy: 0.8106\n",
      "Epoch 99/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4263 - accuracy: 0.7970\n",
      "\n",
      "Epoch 00099: saving model to checkpoints/weights.99.hdf5\n",
      "Epoch 100/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4124 - accuracy: 0.8047\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eef6f352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 - 0s - loss: 0.4451 - accuracy: 0.7929\n",
      "Loss: 0.445065438747406, Accuracy: 0.792914628982544\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model with our test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55ef1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"relu28_relu14_sigmoid_a80.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea28a2",
   "metadata": {},
   "source": [
    "### Just trying differente neurons and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b90c5520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 40)                760       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# Adopting 42 neurons which is something between 2 to 3 times the number of features\n",
    "\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 40\n",
    "hidden_nodes_layer2 = 20\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the strucutre of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cdb2607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e4512873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "292/292 [==============================] - 0s 424us/step - loss: 0.5810 - accuracy: 0.6779\n",
      "Epoch 2/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.4937 - accuracy: 0.7560\n",
      "Epoch 3/100\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.4721 - accuracy: 0.7728\n",
      "Epoch 4/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.4673 - accuracy: 0.7714\n",
      "Epoch 5/100\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.4669 - accuracy: 0.7765\n",
      "Epoch 6/100\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.4626 - accuracy: 0.7746\n",
      "Epoch 7/100\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.4524 - accuracy: 0.7808\n",
      "Epoch 8/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.4668 - accuracy: 0.7722\n",
      "Epoch 9/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.4653 - accuracy: 0.7714\n",
      "\n",
      "Epoch 00009: saving model to checkpoints/weights.09.hdf5\n",
      "Epoch 10/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4565 - accuracy: 0.7827\n",
      "Epoch 11/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.4436 - accuracy: 0.7945\n",
      "Epoch 12/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.4454 - accuracy: 0.7911\n",
      "Epoch 13/100\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.4494 - accuracy: 0.7847\n",
      "Epoch 14/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.4367 - accuracy: 0.7920\n",
      "Epoch 15/100\n",
      "292/292 [==============================] - 0s 432us/step - loss: 0.4408 - accuracy: 0.7931\n",
      "Epoch 16/100\n",
      "292/292 [==============================] - 0s 431us/step - loss: 0.4353 - accuracy: 0.7875\n",
      "Epoch 17/100\n",
      "292/292 [==============================] - 0s 451us/step - loss: 0.4328 - accuracy: 0.7936\n",
      "Epoch 18/100\n",
      "292/292 [==============================] - 0s 432us/step - loss: 0.4177 - accuracy: 0.8019\n",
      "Epoch 19/100\n",
      "292/292 [==============================] - 0s 423us/step - loss: 0.4277 - accuracy: 0.7955\n",
      "\n",
      "Epoch 00019: saving model to checkpoints/weights.19.hdf5\n",
      "Epoch 20/100\n",
      "292/292 [==============================] - 0s 428us/step - loss: 0.4262 - accuracy: 0.7968\n",
      "Epoch 21/100\n",
      "292/292 [==============================] - 0s 423us/step - loss: 0.4171 - accuracy: 0.8012\n",
      "Epoch 22/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.4089 - accuracy: 0.8103\n",
      "Epoch 23/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3956 - accuracy: 0.8115\n",
      "Epoch 24/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4143 - accuracy: 0.8112\n",
      "Epoch 25/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4091 - accuracy: 0.8085\n",
      "Epoch 26/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3999 - accuracy: 0.8143\n",
      "Epoch 27/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3897 - accuracy: 0.8152\n",
      "Epoch 28/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3961 - accuracy: 0.8160\n",
      "Epoch 29/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3931 - accuracy: 0.8230\n",
      "\n",
      "Epoch 00029: saving model to checkpoints/weights.29.hdf5\n",
      "Epoch 30/100\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.3882 - accuracy: 0.8256\n",
      "Epoch 31/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3872 - accuracy: 0.8268\n",
      "Epoch 32/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3945 - accuracy: 0.8163\n",
      "Epoch 33/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3776 - accuracy: 0.8238\n",
      "Epoch 34/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3910 - accuracy: 0.8218\n",
      "Epoch 35/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3856 - accuracy: 0.8231\n",
      "Epoch 36/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3727 - accuracy: 0.8321\n",
      "Epoch 37/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3815 - accuracy: 0.8350\n",
      "Epoch 38/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3837 - accuracy: 0.8234\n",
      "Epoch 39/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3664 - accuracy: 0.8373\n",
      "\n",
      "Epoch 00039: saving model to checkpoints/weights.39.hdf5\n",
      "Epoch 40/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3675 - accuracy: 0.8393\n",
      "Epoch 41/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3677 - accuracy: 0.8349\n",
      "Epoch 42/100\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3649 - accuracy: 0.8328\n",
      "Epoch 43/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3582 - accuracy: 0.8346\n",
      "Epoch 44/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3584 - accuracy: 0.8445\n",
      "Epoch 45/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3608 - accuracy: 0.8403\n",
      "Epoch 46/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3677 - accuracy: 0.8363\n",
      "Epoch 47/100\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.3588 - accuracy: 0.8389\n",
      "Epoch 48/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3559 - accuracy: 0.8423\n",
      "Epoch 49/100\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.3450 - accuracy: 0.8495\n",
      "\n",
      "Epoch 00049: saving model to checkpoints/weights.49.hdf5\n",
      "Epoch 50/100\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.3526 - accuracy: 0.8416\n",
      "Epoch 51/100\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3474 - accuracy: 0.8426\n",
      "Epoch 52/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.3515 - accuracy: 0.8470\n",
      "Epoch 53/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3448 - accuracy: 0.8514\n",
      "Epoch 54/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3531 - accuracy: 0.8412\n",
      "Epoch 55/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3421 - accuracy: 0.8515\n",
      "Epoch 56/100\n",
      "292/292 [==============================] - 0s 430us/step - loss: 0.3454 - accuracy: 0.8495\n",
      "Epoch 57/100\n",
      "292/292 [==============================] - 0s 424us/step - loss: 0.3360 - accuracy: 0.8506\n",
      "Epoch 58/100\n",
      "292/292 [==============================] - 0s 436us/step - loss: 0.3481 - accuracy: 0.8493\n",
      "Epoch 59/100\n",
      "292/292 [==============================] - 0s 422us/step - loss: 0.3332 - accuracy: 0.8558\n",
      "\n",
      "Epoch 00059: saving model to checkpoints/weights.59.hdf5\n",
      "Epoch 60/100\n",
      "292/292 [==============================] - 0s 416us/step - loss: 0.3390 - accuracy: 0.8583\n",
      "Epoch 61/100\n",
      "292/292 [==============================] - 0s 432us/step - loss: 0.3310 - accuracy: 0.8539\n",
      "Epoch 62/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3464 - accuracy: 0.8479\n",
      "Epoch 63/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3413 - accuracy: 0.8580\n",
      "Epoch 64/100\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3352 - accuracy: 0.8540\n",
      "Epoch 65/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3336 - accuracy: 0.8560\n",
      "Epoch 66/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3395 - accuracy: 0.8550\n",
      "Epoch 67/100\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3301 - accuracy: 0.8537\n",
      "Epoch 68/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3277 - accuracy: 0.8590\n",
      "Epoch 69/100\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3294 - accuracy: 0.8556\n",
      "\n",
      "Epoch 00069: saving model to checkpoints/weights.69.hdf5\n",
      "Epoch 70/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3402 - accuracy: 0.8554\n",
      "Epoch 71/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3211 - accuracy: 0.8645\n",
      "Epoch 72/100\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3265 - accuracy: 0.8578\n",
      "Epoch 73/100\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.3362 - accuracy: 0.8529\n",
      "Epoch 74/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3284 - accuracy: 0.8599\n",
      "Epoch 75/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3204 - accuracy: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "292/292 [==============================] - 0s 447us/step - loss: 0.3259 - accuracy: 0.8594\n",
      "Epoch 77/100\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3235 - accuracy: 0.8600\n",
      "Epoch 78/100\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3265 - accuracy: 0.8626\n",
      "Epoch 79/100\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3287 - accuracy: 0.8603\n",
      "\n",
      "Epoch 00079: saving model to checkpoints/weights.79.hdf5\n",
      "Epoch 80/100\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3241 - accuracy: 0.8593\n",
      "Epoch 81/100\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3251 - accuracy: 0.8599\n",
      "Epoch 82/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3336 - accuracy: 0.8568\n",
      "Epoch 83/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3226 - accuracy: 0.8619\n",
      "Epoch 84/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3212 - accuracy: 0.8628\n",
      "Epoch 85/100\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3322 - accuracy: 0.8538\n",
      "Epoch 86/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3230 - accuracy: 0.8584\n",
      "Epoch 87/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3186 - accuracy: 0.8629\n",
      "Epoch 88/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3186 - accuracy: 0.8642\n",
      "Epoch 89/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3124 - accuracy: 0.8751\n",
      "\n",
      "Epoch 00089: saving model to checkpoints/weights.89.hdf5\n",
      "Epoch 90/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3143 - accuracy: 0.8638\n",
      "Epoch 91/100\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3087 - accuracy: 0.8697\n",
      "Epoch 92/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3130 - accuracy: 0.8676\n",
      "Epoch 93/100\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3070 - accuracy: 0.8735\n",
      "Epoch 94/100\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3268 - accuracy: 0.8577\n",
      "Epoch 95/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3064 - accuracy: 0.8703\n",
      "Epoch 96/100\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3166 - accuracy: 0.8635\n",
      "Epoch 97/100\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3088 - accuracy: 0.8689\n",
      "Epoch 98/100\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3108 - accuracy: 0.8735\n",
      "Epoch 99/100\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3030 - accuracy: 0.8716\n",
      "\n",
      "Epoch 00099: saving model to checkpoints/weights.99.hdf5\n",
      "Epoch 100/100\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3112 - accuracy: 0.8683\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d8f10613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 - 0s - loss: 0.4441 - accuracy: 0.8187\n",
      "Loss: 0.44413119554519653, Accuracy: 0.8186795711517334\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model with our test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae19c8",
   "metadata": {},
   "source": [
    "## Slowly but surely\n",
    "\n",
    "Removing more columns and analysing the impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ebf6b47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1624\n",
       "0     1262\n",
       "7     1237\n",
       "2     1180\n",
       "9     1088\n",
       "11    1082\n",
       "5     1036\n",
       "8      933\n",
       "10     916\n",
       "6      880\n",
       "4      864\n",
       "3      317\n",
       "Name: key, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df.key.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6475a59f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popular</th>\n",
       "      <th>genre_1_Electronic</th>\n",
       "      <th>genre_1_Indie</th>\n",
       "      <th>genre_1_Latin</th>\n",
       "      <th>genre_1_Other</th>\n",
       "      <th>genre_1_Pop</th>\n",
       "      <th>genre_1_Rap</th>\n",
       "      <th>genre_1_Rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "      <td>90.031</td>\n",
       "      <td>186964</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  speechiness  acousticness  \\\n",
       "0         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "1         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "2         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "3         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "4         0.798   0.697    0    -7.139       0.0891        0.0202   \n",
       "\n",
       "   instrumentalness  liveness  valence   tempo  duration_ms  popularity  \\\n",
       "0               0.0     0.259    0.745  90.031       186964          88   \n",
       "1               0.0     0.259    0.745  90.031       186964          87   \n",
       "2               0.0     0.259    0.745  90.031       186964          87   \n",
       "3               0.0     0.259    0.745  90.031       186964          87   \n",
       "4               0.0     0.259    0.745  90.031       186964          87   \n",
       "\n",
       "   popular  genre_1_Electronic  genre_1_Indie  genre_1_Latin  genre_1_Other  \\\n",
       "0        1                 0.0            0.0            0.0            1.0   \n",
       "1        1                 0.0            0.0            0.0            0.0   \n",
       "2        1                 0.0            0.0            0.0            0.0   \n",
       "3        1                 0.0            0.0            0.0            0.0   \n",
       "4        1                 0.0            0.0            0.0            0.0   \n",
       "\n",
       "   genre_1_Pop  genre_1_Rap  genre_1_Rock  \n",
       "0          0.0          0.0           0.0  \n",
       "1          1.0          0.0           0.0  \n",
       "2          1.0          0.0           0.0  \n",
       "3          1.0          0.0           0.0  \n",
       "4          1.0          0.0           0.0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = save2_ml_df.copy()\n",
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f010ed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.697</td>\n",
       "      <td>-7.139</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  loudness  speechiness  acousticness  \\\n",
       "0         0.798   0.697    -7.139       0.0891        0.0202   \n",
       "1         0.798   0.697    -7.139       0.0891        0.0202   \n",
       "2         0.798   0.697    -7.139       0.0891        0.0202   \n",
       "3         0.798   0.697    -7.139       0.0891        0.0202   \n",
       "4         0.798   0.697    -7.139       0.0891        0.0202   \n",
       "\n",
       "   instrumentalness  liveness  valence  \n",
       "0               0.0     0.259    0.745  \n",
       "1               0.0     0.259    0.745  \n",
       "2               0.0     0.259    0.745  \n",
       "3               0.0     0.259    0.745  \n",
       "4               0.0     0.259    0.745  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "337cde72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2e53b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the preprocessed data into features and targets\n",
    "\n",
    "X = ml_df.drop(columns=['popular', 'popularity','duration_ms','tempo','key',\n",
    "                        'genre_1_Electronic','genre_1_Indie','genre_1_Latin','genre_1_Other','genre_1_Pop',\n",
    "                        'genre_1_Rap','genre_1_Rock'])\n",
    "y = ml_df['popular'].values\n",
    "\n",
    "# Training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) # Test size is 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3644152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f1c04b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# Adopting 42 neurons which is something between 2 to 3 times the number of features\n",
    "\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 12\n",
    "hidden_nodes_layer2 = 6\n",
    "# hidden_nodes_layer3 = 20\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# # Third hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the strucutre of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fbdee39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0f48484c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "292/292 [==============================] - 0s 386us/step - loss: 0.7206 - accuracy: 0.5187\n",
      "Epoch 2/120\n",
      "292/292 [==============================] - 0s 370us/step - loss: 0.6025 - accuracy: 0.6805\n",
      "Epoch 3/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5823 - accuracy: 0.6829\n",
      "Epoch 4/120\n",
      "292/292 [==============================] - 0s 360us/step - loss: 0.5700 - accuracy: 0.6952\n",
      "Epoch 5/120\n",
      "292/292 [==============================] - 0s 362us/step - loss: 0.5607 - accuracy: 0.7039\n",
      "Epoch 6/120\n",
      "292/292 [==============================] - 0s 362us/step - loss: 0.5565 - accuracy: 0.7130\n",
      "Epoch 7/120\n",
      "292/292 [==============================] - 0s 365us/step - loss: 0.5602 - accuracy: 0.7065\n",
      "Epoch 8/120\n",
      "292/292 [==============================] - 0s 377us/step - loss: 0.5587 - accuracy: 0.7081\n",
      "Epoch 9/120\n",
      "292/292 [==============================] - 0s 387us/step - loss: 0.5601 - accuracy: 0.7078\n",
      "\n",
      "Epoch 00009: saving model to checkpoints/weights.09.hdf5\n",
      "Epoch 10/120\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.5600 - accuracy: 0.7056\n",
      "Epoch 11/120\n",
      "292/292 [==============================] - 0s 382us/step - loss: 0.5494 - accuracy: 0.7156\n",
      "Epoch 12/120\n",
      "292/292 [==============================] - 0s 482us/step - loss: 0.5552 - accuracy: 0.7174\n",
      "Epoch 13/120\n",
      "292/292 [==============================] - 0s 467us/step - loss: 0.5547 - accuracy: 0.7189\n",
      "Epoch 14/120\n",
      "292/292 [==============================] - 0s 423us/step - loss: 0.5472 - accuracy: 0.7237\n",
      "Epoch 15/120\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.5450 - accuracy: 0.7203\n",
      "Epoch 16/120\n",
      "292/292 [==============================] - 0s 441us/step - loss: 0.5450 - accuracy: 0.7254\n",
      "Epoch 17/120\n",
      "292/292 [==============================] - 0s 386us/step - loss: 0.5427 - accuracy: 0.7331\n",
      "Epoch 18/120\n",
      "292/292 [==============================] - 0s 354us/step - loss: 0.5486 - accuracy: 0.7265\n",
      "Epoch 19/120\n",
      "292/292 [==============================] - 0s 366us/step - loss: 0.5442 - accuracy: 0.7295\n",
      "\n",
      "Epoch 00019: saving model to checkpoints/weights.19.hdf5\n",
      "Epoch 20/120\n",
      "292/292 [==============================] - 0s 384us/step - loss: 0.5417 - accuracy: 0.7334\n",
      "Epoch 21/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5431 - accuracy: 0.7288\n",
      "Epoch 22/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5418 - accuracy: 0.7310\n",
      "Epoch 23/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5507 - accuracy: 0.7236\n",
      "Epoch 24/120\n",
      "292/292 [==============================] - 0s 358us/step - loss: 0.5436 - accuracy: 0.7287\n",
      "Epoch 25/120\n",
      "292/292 [==============================] - 0s 360us/step - loss: 0.5499 - accuracy: 0.7266\n",
      "Epoch 26/120\n",
      "292/292 [==============================] - 0s 358us/step - loss: 0.5362 - accuracy: 0.7339\n",
      "Epoch 27/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5286 - accuracy: 0.7365\n",
      "Epoch 28/120\n",
      "292/292 [==============================] - 0s 358us/step - loss: 0.5361 - accuracy: 0.7322\n",
      "Epoch 29/120\n",
      "292/292 [==============================] - 0s 357us/step - loss: 0.5360 - accuracy: 0.7391\n",
      "\n",
      "Epoch 00029: saving model to checkpoints/weights.29.hdf5\n",
      "Epoch 30/120\n",
      "292/292 [==============================] - 0s 355us/step - loss: 0.5383 - accuracy: 0.7385\n",
      "Epoch 31/120\n",
      "292/292 [==============================] - 0s 360us/step - loss: 0.5351 - accuracy: 0.7382\n",
      "Epoch 32/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5338 - accuracy: 0.7383\n",
      "Epoch 33/120\n",
      "292/292 [==============================] - 0s 360us/step - loss: 0.5299 - accuracy: 0.7444\n",
      "Epoch 34/120\n",
      "292/292 [==============================] - 0s 360us/step - loss: 0.5291 - accuracy: 0.7474\n",
      "Epoch 35/120\n",
      "292/292 [==============================] - 0s 365us/step - loss: 0.5366 - accuracy: 0.7400\n",
      "Epoch 36/120\n",
      "292/292 [==============================] - 0s 363us/step - loss: 0.5327 - accuracy: 0.7359\n",
      "Epoch 37/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5317 - accuracy: 0.7417\n",
      "Epoch 38/120\n",
      "292/292 [==============================] - 0s 363us/step - loss: 0.5360 - accuracy: 0.7406\n",
      "Epoch 39/120\n",
      "292/292 [==============================] - 0s 363us/step - loss: 0.5336 - accuracy: 0.7339\n",
      "\n",
      "Epoch 00039: saving model to checkpoints/weights.39.hdf5\n",
      "Epoch 40/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5375 - accuracy: 0.7381\n",
      "Epoch 41/120\n",
      "292/292 [==============================] - 0s 363us/step - loss: 0.5306 - accuracy: 0.7363\n",
      "Epoch 42/120\n",
      "292/292 [==============================] - 0s 365us/step - loss: 0.5294 - accuracy: 0.7464\n",
      "Epoch 43/120\n",
      "292/292 [==============================] - 0s 368us/step - loss: 0.5379 - accuracy: 0.7370\n",
      "Epoch 44/120\n",
      "292/292 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7393\n",
      "Epoch 45/120\n",
      "292/292 [==============================] - 0s 571us/step - loss: 0.5276 - accuracy: 0.7434\n",
      "Epoch 46/120\n",
      "292/292 [==============================] - 0s 374us/step - loss: 0.5302 - accuracy: 0.7469\n",
      "Epoch 47/120\n",
      "292/292 [==============================] - 0s 366us/step - loss: 0.5339 - accuracy: 0.7405\n",
      "Epoch 48/120\n",
      "292/292 [==============================] - 0s 367us/step - loss: 0.5178 - accuracy: 0.7481\n",
      "Epoch 49/120\n",
      "292/292 [==============================] - 0s 370us/step - loss: 0.5239 - accuracy: 0.7474\n",
      "\n",
      "Epoch 00049: saving model to checkpoints/weights.49.hdf5\n",
      "Epoch 50/120\n",
      "292/292 [==============================] - 0s 375us/step - loss: 0.5317 - accuracy: 0.7353\n",
      "Epoch 51/120\n",
      "292/292 [==============================] - 0s 457us/step - loss: 0.5227 - accuracy: 0.7457\n",
      "Epoch 52/120\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.5274 - accuracy: 0.7466\n",
      "Epoch 53/120\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.5274 - accuracy: 0.7402\n",
      "Epoch 54/120\n",
      "292/292 [==============================] - 0s 378us/step - loss: 0.5257 - accuracy: 0.7396\n",
      "Epoch 55/120\n",
      "292/292 [==============================] - 0s 371us/step - loss: 0.5245 - accuracy: 0.7351\n",
      "Epoch 56/120\n",
      "292/292 [==============================] - 0s 371us/step - loss: 0.5289 - accuracy: 0.7356\n",
      "Epoch 57/120\n",
      "292/292 [==============================] - 0s 370us/step - loss: 0.5234 - accuracy: 0.7435\n",
      "Epoch 58/120\n",
      "292/292 [==============================] - 0s 368us/step - loss: 0.5258 - accuracy: 0.7363\n",
      "Epoch 59/120\n",
      "292/292 [==============================] - 0s 368us/step - loss: 0.5298 - accuracy: 0.7346\n",
      "\n",
      "Epoch 00059: saving model to checkpoints/weights.59.hdf5\n",
      "Epoch 60/120\n",
      "292/292 [==============================] - 0s 385us/step - loss: 0.5249 - accuracy: 0.7401\n",
      "Epoch 61/120\n",
      "292/292 [==============================] - 0s 367us/step - loss: 0.5247 - accuracy: 0.7431\n",
      "Epoch 62/120\n",
      "292/292 [==============================] - 0s 367us/step - loss: 0.5284 - accuracy: 0.7396\n",
      "Epoch 63/120\n",
      "292/292 [==============================] - 0s 365us/step - loss: 0.5260 - accuracy: 0.7460\n",
      "Epoch 64/120\n",
      "292/292 [==============================] - 0s 367us/step - loss: 0.5285 - accuracy: 0.7413\n",
      "Epoch 65/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5211 - accuracy: 0.7471\n",
      "Epoch 66/120\n",
      "292/292 [==============================] - 0s 366us/step - loss: 0.5144 - accuracy: 0.7521\n",
      "Epoch 67/120\n",
      "292/292 [==============================] - 0s 368us/step - loss: 0.5244 - accuracy: 0.7461\n",
      "Epoch 68/120\n",
      "292/292 [==============================] - 0s 372us/step - loss: 0.5194 - accuracy: 0.7417\n",
      "Epoch 69/120\n",
      "292/292 [==============================] - 0s 370us/step - loss: 0.5288 - accuracy: 0.7397\n",
      "\n",
      "Epoch 00069: saving model to checkpoints/weights.69.hdf5\n",
      "Epoch 70/120\n",
      "292/292 [==============================] - 0s 378us/step - loss: 0.5223 - accuracy: 0.7418\n",
      "Epoch 71/120\n",
      "292/292 [==============================] - 0s 386us/step - loss: 0.5252 - accuracy: 0.7419\n",
      "Epoch 72/120\n",
      "292/292 [==============================] - 0s 374us/step - loss: 0.5252 - accuracy: 0.7485\n",
      "Epoch 73/120\n",
      "292/292 [==============================] - 0s 367us/step - loss: 0.5234 - accuracy: 0.7439\n",
      "Epoch 74/120\n",
      "292/292 [==============================] - 0s 366us/step - loss: 0.5221 - accuracy: 0.7435\n",
      "Epoch 75/120\n",
      "292/292 [==============================] - 0s 377us/step - loss: 0.5271 - accuracy: 0.7444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5341 - accuracy: 0.7366\n",
      "Epoch 77/120\n",
      "292/292 [==============================] - 0s 364us/step - loss: 0.5180 - accuracy: 0.7444\n",
      "Epoch 78/120\n",
      "292/292 [==============================] - 0s 355us/step - loss: 0.5219 - accuracy: 0.7436\n",
      "Epoch 79/120\n",
      "292/292 [==============================] - 0s 371us/step - loss: 0.5223 - accuracy: 0.7482\n",
      "\n",
      "Epoch 00079: saving model to checkpoints/weights.79.hdf5\n",
      "Epoch 80/120\n",
      "292/292 [==============================] - 0s 356us/step - loss: 0.5246 - accuracy: 0.7436\n",
      "Epoch 81/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5206 - accuracy: 0.7397\n",
      "Epoch 82/120\n",
      "292/292 [==============================] - 0s 352us/step - loss: 0.5248 - accuracy: 0.7370\n",
      "Epoch 83/120\n",
      "292/292 [==============================] - 0s 354us/step - loss: 0.5168 - accuracy: 0.7483\n",
      "Epoch 84/120\n",
      "292/292 [==============================] - 0s 352us/step - loss: 0.5281 - accuracy: 0.7406\n",
      "Epoch 85/120\n",
      "292/292 [==============================] - 0s 356us/step - loss: 0.5241 - accuracy: 0.7430\n",
      "Epoch 86/120\n",
      "292/292 [==============================] - 0s 357us/step - loss: 0.5136 - accuracy: 0.7501\n",
      "Epoch 87/120\n",
      "292/292 [==============================] - 0s 356us/step - loss: 0.5231 - accuracy: 0.7418\n",
      "Epoch 88/120\n",
      "292/292 [==============================] - 0s 373us/step - loss: 0.5196 - accuracy: 0.7391\n",
      "Epoch 89/120\n",
      "292/292 [==============================] - 0s 376us/step - loss: 0.5268 - accuracy: 0.7430\n",
      "\n",
      "Epoch 00089: saving model to checkpoints/weights.89.hdf5\n",
      "Epoch 90/120\n",
      "292/292 [==============================] - 0s 372us/step - loss: 0.5172 - accuracy: 0.7479\n",
      "Epoch 91/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5269 - accuracy: 0.7354\n",
      "Epoch 92/120\n",
      "292/292 [==============================] - 0s 362us/step - loss: 0.5141 - accuracy: 0.7540\n",
      "Epoch 93/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5170 - accuracy: 0.7413\n",
      "Epoch 94/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5181 - accuracy: 0.7434\n",
      "Epoch 95/120\n",
      "292/292 [==============================] - 0s 459us/step - loss: 0.5120 - accuracy: 0.7524\n",
      "Epoch 96/120\n",
      "292/292 [==============================] - 0s 368us/step - loss: 0.5194 - accuracy: 0.7494\n",
      "Epoch 97/120\n",
      "292/292 [==============================] - 0s 365us/step - loss: 0.5193 - accuracy: 0.7436\n",
      "Epoch 98/120\n",
      "292/292 [==============================] - 0s 362us/step - loss: 0.5228 - accuracy: 0.7464\n",
      "Epoch 99/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5169 - accuracy: 0.7478\n",
      "\n",
      "Epoch 00099: saving model to checkpoints/weights.99.hdf5\n",
      "Epoch 100/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5206 - accuracy: 0.7415\n",
      "Epoch 101/120\n",
      "292/292 [==============================] - 0s 354us/step - loss: 0.5177 - accuracy: 0.7400\n",
      "Epoch 102/120\n",
      "292/292 [==============================] - 0s 355us/step - loss: 0.5223 - accuracy: 0.7397\n",
      "Epoch 103/120\n",
      "292/292 [==============================] - 0s 356us/step - loss: 0.5287 - accuracy: 0.7389\n",
      "Epoch 104/120\n",
      "292/292 [==============================] - 0s 358us/step - loss: 0.5156 - accuracy: 0.7419\n",
      "Epoch 105/120\n",
      "292/292 [==============================] - 0s 358us/step - loss: 0.5205 - accuracy: 0.7405\n",
      "Epoch 106/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5172 - accuracy: 0.7500\n",
      "Epoch 107/120\n",
      "292/292 [==============================] - 0s 358us/step - loss: 0.5119 - accuracy: 0.7548\n",
      "Epoch 108/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5092 - accuracy: 0.7498\n",
      "Epoch 109/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5127 - accuracy: 0.7487\n",
      "\n",
      "Epoch 00109: saving model to checkpoints/weights.109.hdf5\n",
      "Epoch 110/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5208 - accuracy: 0.7383\n",
      "Epoch 111/120\n",
      "292/292 [==============================] - 0s 360us/step - loss: 0.5170 - accuracy: 0.7455\n",
      "Epoch 112/120\n",
      "292/292 [==============================] - 0s 360us/step - loss: 0.5179 - accuracy: 0.7449\n",
      "Epoch 113/120\n",
      "292/292 [==============================] - 0s 360us/step - loss: 0.5269 - accuracy: 0.7413\n",
      "Epoch 114/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5231 - accuracy: 0.7413\n",
      "Epoch 115/120\n",
      "292/292 [==============================] - 0s 359us/step - loss: 0.5124 - accuracy: 0.7464\n",
      "Epoch 116/120\n",
      "292/292 [==============================] - 0s 362us/step - loss: 0.5221 - accuracy: 0.7474\n",
      "Epoch 117/120\n",
      "292/292 [==============================] - 0s 370us/step - loss: 0.5155 - accuracy: 0.7456\n",
      "Epoch 118/120\n",
      "292/292 [==============================] - 0s 366us/step - loss: 0.5153 - accuracy: 0.7433\n",
      "Epoch 119/120\n",
      "292/292 [==============================] - 0s 361us/step - loss: 0.5168 - accuracy: 0.7496\n",
      "\n",
      "Epoch 00119: saving model to checkpoints/weights.119.hdf5\n",
      "Epoch 120/120\n",
      "292/292 [==============================] - 0s 364us/step - loss: 0.5234 - accuracy: 0.7452\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=120,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "eaac498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 346us/step - loss: 0.5457 - accuracy: 0.7253\n",
      "Loss: 0.5457160472869873, Accuracy: 0.7252817749977112\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model with our test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f8968",
   "metadata": {},
   "source": [
    "### Original attempt but with more epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "05329ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the preprocessed data into features and targets\n",
    "\n",
    "X = ml_df.drop(columns=['popular', 'popularity'])\n",
    "y = ml_df['popular'].values\n",
    "\n",
    "# Training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) # Test size is 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "dac2918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1206dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 28)                532       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 953\n",
      "Trainable params: 953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# Adopting 42 neurons which is something between 2 to 3 times the number of features\n",
    "\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 28\n",
    "hidden_nodes_layer2 = 14\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the strucutre of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c361394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "302f8fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "292/292 [==============================] - 0s 423us/step - loss: 0.6252 - accuracy: 0.6286\n",
      "Epoch 2/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.5161 - accuracy: 0.7481\n",
      "Epoch 3/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4873 - accuracy: 0.7547\n",
      "Epoch 4/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.4825 - accuracy: 0.7609\n",
      "Epoch 5/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4777 - accuracy: 0.7726\n",
      "Epoch 6/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.4646 - accuracy: 0.7821\n",
      "Epoch 7/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.4628 - accuracy: 0.7806\n",
      "Epoch 8/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4549 - accuracy: 0.7810\n",
      "Epoch 9/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.4523 - accuracy: 0.7853\n",
      "Epoch 10/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.4495 - accuracy: 0.7876\n",
      "Epoch 11/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4463 - accuracy: 0.7849\n",
      "Epoch 12/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4559 - accuracy: 0.7826\n",
      "Epoch 13/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4465 - accuracy: 0.7875\n",
      "Epoch 14/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4321 - accuracy: 0.7953\n",
      "Epoch 15/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.4418 - accuracy: 0.7883\n",
      "Epoch 16/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4389 - accuracy: 0.7927\n",
      "Epoch 17/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.4347 - accuracy: 0.7938\n",
      "Epoch 18/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4413 - accuracy: 0.7896\n",
      "Epoch 19/500\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.4423 - accuracy: 0.7897\n",
      "Epoch 20/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.4280 - accuracy: 0.7929\n",
      "Epoch 21/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4314 - accuracy: 0.7876\n",
      "Epoch 22/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.4263 - accuracy: 0.7968\n",
      "Epoch 23/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.4293 - accuracy: 0.7990\n",
      "Epoch 24/500\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.4407 - accuracy: 0.7877\n",
      "Epoch 25/500\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.4268 - accuracy: 0.7943\n",
      "Epoch 26/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.4189 - accuracy: 0.8075\n",
      "Epoch 27/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.4193 - accuracy: 0.8052\n",
      "Epoch 28/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4173 - accuracy: 0.8038\n",
      "Epoch 29/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.4224 - accuracy: 0.8013\n",
      "Epoch 30/500\n",
      "292/292 [==============================] - 0s 433us/step - loss: 0.4199 - accuracy: 0.7979\n",
      "Epoch 31/500\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.4066 - accuracy: 0.8125\n",
      "Epoch 32/500\n",
      "292/292 [==============================] - 0s 425us/step - loss: 0.4138 - accuracy: 0.8051\n",
      "Epoch 33/500\n",
      "292/292 [==============================] - 0s 432us/step - loss: 0.4219 - accuracy: 0.8061\n",
      "Epoch 34/500\n",
      "292/292 [==============================] - 0s 421us/step - loss: 0.4102 - accuracy: 0.8102\n",
      "Epoch 35/500\n",
      "292/292 [==============================] - 0s 432us/step - loss: 0.4150 - accuracy: 0.8064\n",
      "Epoch 36/500\n",
      "292/292 [==============================] - 0s 480us/step - loss: 0.4096 - accuracy: 0.8099\n",
      "Epoch 37/500\n",
      "292/292 [==============================] - 0s 562us/step - loss: 0.4104 - accuracy: 0.8103\n",
      "Epoch 38/500\n",
      "292/292 [==============================] - 0s 455us/step - loss: 0.4086 - accuracy: 0.8087\n",
      "Epoch 39/500\n",
      "292/292 [==============================] - 0s 423us/step - loss: 0.4044 - accuracy: 0.8128\n",
      "Epoch 40/500\n",
      "292/292 [==============================] - 0s 425us/step - loss: 0.4115 - accuracy: 0.8133\n",
      "\n",
      "Epoch 00040: saving model to checkpoints2/weights.40.hdf5\n",
      "Epoch 41/500\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3978 - accuracy: 0.8149\n",
      "Epoch 42/500\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.3963 - accuracy: 0.8191\n",
      "Epoch 43/500\n",
      "292/292 [==============================] - 0s 419us/step - loss: 0.4055 - accuracy: 0.8130\n",
      "Epoch 44/500\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.3937 - accuracy: 0.8190\n",
      "Epoch 45/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.4043 - accuracy: 0.8165\n",
      "Epoch 46/500\n",
      "292/292 [==============================] - 0s 423us/step - loss: 0.4021 - accuracy: 0.8156\n",
      "Epoch 47/500\n",
      "292/292 [==============================] - 0s 428us/step - loss: 0.4020 - accuracy: 0.8113\n",
      "Epoch 48/500\n",
      "292/292 [==============================] - 0s 455us/step - loss: 0.3934 - accuracy: 0.8200\n",
      "Epoch 49/500\n",
      "292/292 [==============================] - 0s 437us/step - loss: 0.4035 - accuracy: 0.8078\n",
      "Epoch 50/500\n",
      "292/292 [==============================] - 0s 440us/step - loss: 0.3961 - accuracy: 0.8138\n",
      "Epoch 51/500\n",
      "292/292 [==============================] - 0s 479us/step - loss: 0.3829 - accuracy: 0.8198\n",
      "Epoch 52/500\n",
      "292/292 [==============================] - 0s 417us/step - loss: 0.3980 - accuracy: 0.8197\n",
      "Epoch 53/500\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.3930 - accuracy: 0.8196\n",
      "Epoch 54/500\n",
      "292/292 [==============================] - 0s 465us/step - loss: 0.4011 - accuracy: 0.8128\n",
      "Epoch 55/500\n",
      "292/292 [==============================] - 0s 463us/step - loss: 0.3889 - accuracy: 0.8191\n",
      "Epoch 56/500\n",
      "292/292 [==============================] - 0s 487us/step - loss: 0.3894 - accuracy: 0.8232\n",
      "Epoch 57/500\n",
      "292/292 [==============================] - 0s 646us/step - loss: 0.3852 - accuracy: 0.8251\n",
      "Epoch 58/500\n",
      "292/292 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8143\n",
      "Epoch 59/500\n",
      "292/292 [==============================] - 0s 476us/step - loss: 0.3868 - accuracy: 0.8225\n",
      "Epoch 60/500\n",
      "292/292 [==============================] - 0s 504us/step - loss: 0.3844 - accuracy: 0.8299\n",
      "Epoch 61/500\n",
      "292/292 [==============================] - 0s 581us/step - loss: 0.3856 - accuracy: 0.8253\n",
      "Epoch 62/500\n",
      "292/292 [==============================] - 0s 502us/step - loss: 0.3866 - accuracy: 0.8235\n",
      "Epoch 63/500\n",
      "292/292 [==============================] - 0s 684us/step - loss: 0.3755 - accuracy: 0.8282\n",
      "Epoch 64/500\n",
      "292/292 [==============================] - 0s 497us/step - loss: 0.3794 - accuracy: 0.8284\n",
      "Epoch 65/500\n",
      "292/292 [==============================] - 0s 515us/step - loss: 0.3815 - accuracy: 0.8313\n",
      "Epoch 66/500\n",
      "292/292 [==============================] - 0s 504us/step - loss: 0.3835 - accuracy: 0.8244\n",
      "Epoch 67/500\n",
      "292/292 [==============================] - 0s 525us/step - loss: 0.3851 - accuracy: 0.8262\n",
      "Epoch 68/500\n",
      "292/292 [==============================] - 0s 550us/step - loss: 0.3887 - accuracy: 0.8222\n",
      "Epoch 69/500\n",
      "292/292 [==============================] - 0s 503us/step - loss: 0.3766 - accuracy: 0.8289\n",
      "Epoch 70/500\n",
      "292/292 [==============================] - 0s 511us/step - loss: 0.3947 - accuracy: 0.8190\n",
      "Epoch 71/500\n",
      "292/292 [==============================] - 0s 519us/step - loss: 0.3805 - accuracy: 0.8285\n",
      "Epoch 72/500\n",
      "292/292 [==============================] - 0s 525us/step - loss: 0.3785 - accuracy: 0.8306\n",
      "Epoch 73/500\n",
      "292/292 [==============================] - 0s 681us/step - loss: 0.3828 - accuracy: 0.8252\n",
      "Epoch 74/500\n",
      "292/292 [==============================] - 0s 608us/step - loss: 0.3780 - accuracy: 0.8286\n",
      "Epoch 75/500\n",
      "292/292 [==============================] - 0s 582us/step - loss: 0.3739 - accuracy: 0.8290\n",
      "Epoch 76/500\n",
      "292/292 [==============================] - 0s 509us/step - loss: 0.3767 - accuracy: 0.8305\n",
      "Epoch 77/500\n",
      "292/292 [==============================] - 0s 594us/step - loss: 0.3702 - accuracy: 0.8303\n",
      "Epoch 78/500\n",
      "292/292 [==============================] - 0s 540us/step - loss: 0.3817 - accuracy: 0.8221\n",
      "Epoch 79/500\n",
      "292/292 [==============================] - 0s 948us/step - loss: 0.3827 - accuracy: 0.8227\n",
      "Epoch 80/500\n",
      "292/292 [==============================] - 0s 450us/step - loss: 0.3738 - accuracy: 0.8291\n",
      "Epoch 81/500\n",
      "292/292 [==============================] - 0s 452us/step - loss: 0.3702 - accuracy: 0.8321\n",
      "Epoch 82/500\n",
      "292/292 [==============================] - 0s 545us/step - loss: 0.3764 - accuracy: 0.8287\n",
      "Epoch 83/500\n",
      "292/292 [==============================] - 0s 470us/step - loss: 0.3692 - accuracy: 0.8349\n",
      "Epoch 84/500\n",
      "292/292 [==============================] - 0s 455us/step - loss: 0.3664 - accuracy: 0.8407\n",
      "Epoch 85/500\n",
      "292/292 [==============================] - 0s 454us/step - loss: 0.3803 - accuracy: 0.8345\n",
      "Epoch 86/500\n",
      "292/292 [==============================] - 0s 444us/step - loss: 0.3695 - accuracy: 0.8315\n",
      "Epoch 87/500\n",
      "292/292 [==============================] - 0s 455us/step - loss: 0.3768 - accuracy: 0.8276\n",
      "Epoch 88/500\n",
      "292/292 [==============================] - 0s 445us/step - loss: 0.3703 - accuracy: 0.8333\n",
      "Epoch 89/500\n",
      "292/292 [==============================] - 0s 456us/step - loss: 0.3660 - accuracy: 0.8318\n",
      "Epoch 90/500\n",
      "292/292 [==============================] - 0s 464us/step - loss: 0.3722 - accuracy: 0.8310\n",
      "Epoch 91/500\n",
      "292/292 [==============================] - 0s 459us/step - loss: 0.3702 - accuracy: 0.8385\n",
      "Epoch 92/500\n",
      "292/292 [==============================] - 0s 459us/step - loss: 0.3642 - accuracy: 0.8407\n",
      "Epoch 93/500\n",
      "292/292 [==============================] - 0s 472us/step - loss: 0.3655 - accuracy: 0.8344\n",
      "Epoch 94/500\n",
      "292/292 [==============================] - 0s 471us/step - loss: 0.3704 - accuracy: 0.8311\n",
      "Epoch 95/500\n",
      "292/292 [==============================] - 0s 462us/step - loss: 0.3557 - accuracy: 0.8386\n",
      "Epoch 96/500\n",
      "292/292 [==============================] - 0s 447us/step - loss: 0.3755 - accuracy: 0.8321\n",
      "Epoch 97/500\n",
      "292/292 [==============================] - 0s 493us/step - loss: 0.3707 - accuracy: 0.8301\n",
      "Epoch 98/500\n",
      "292/292 [==============================] - 0s 457us/step - loss: 0.3697 - accuracy: 0.8368\n",
      "Epoch 99/500\n",
      "292/292 [==============================] - 0s 450us/step - loss: 0.3554 - accuracy: 0.8416\n",
      "Epoch 100/500\n",
      "292/292 [==============================] - 0s 459us/step - loss: 0.3589 - accuracy: 0.8406\n",
      "Epoch 101/500\n",
      "292/292 [==============================] - 0s 457us/step - loss: 0.3734 - accuracy: 0.8259\n",
      "Epoch 102/500\n",
      "292/292 [==============================] - 0s 458us/step - loss: 0.3619 - accuracy: 0.8400\n",
      "Epoch 103/500\n",
      "292/292 [==============================] - 0s 455us/step - loss: 0.3547 - accuracy: 0.8473\n",
      "Epoch 104/500\n",
      "292/292 [==============================] - 0s 460us/step - loss: 0.3509 - accuracy: 0.8482\n",
      "Epoch 105/500\n",
      "292/292 [==============================] - 0s 466us/step - loss: 0.3605 - accuracy: 0.8396\n",
      "Epoch 106/500\n",
      "292/292 [==============================] - 0s 470us/step - loss: 0.3582 - accuracy: 0.8433\n",
      "Epoch 107/500\n",
      "292/292 [==============================] - 0s 518us/step - loss: 0.3697 - accuracy: 0.8381\n",
      "Epoch 108/500\n",
      "292/292 [==============================] - 0s 470us/step - loss: 0.3660 - accuracy: 0.8348\n",
      "Epoch 109/500\n",
      "292/292 [==============================] - 0s 470us/step - loss: 0.3540 - accuracy: 0.8419\n",
      "Epoch 110/500\n",
      "292/292 [==============================] - 0s 469us/step - loss: 0.3572 - accuracy: 0.8439\n",
      "Epoch 111/500\n",
      "292/292 [==============================] - 0s 493us/step - loss: 0.3680 - accuracy: 0.8339\n",
      "Epoch 112/500\n",
      "292/292 [==============================] - 0s 458us/step - loss: 0.3589 - accuracy: 0.8386\n",
      "Epoch 113/500\n",
      "292/292 [==============================] - 0s 458us/step - loss: 0.3595 - accuracy: 0.8393\n",
      "Epoch 114/500\n",
      "292/292 [==============================] - 0s 443us/step - loss: 0.3439 - accuracy: 0.8471\n",
      "Epoch 115/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3531 - accuracy: 0.8429\n",
      "Epoch 116/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3560 - accuracy: 0.8405\n",
      "Epoch 117/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3527 - accuracy: 0.8433\n",
      "Epoch 118/500\n",
      "292/292 [==============================] - 0s 428us/step - loss: 0.3704 - accuracy: 0.8378\n",
      "Epoch 119/500\n",
      "292/292 [==============================] - 0s 459us/step - loss: 0.3540 - accuracy: 0.8446\n",
      "Epoch 120/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3444 - accuracy: 0.8470\n",
      "Epoch 121/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3512 - accuracy: 0.8455\n",
      "Epoch 122/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3482 - accuracy: 0.8489\n",
      "Epoch 123/500\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3618 - accuracy: 0.8383\n",
      "Epoch 124/500\n",
      "292/292 [==============================] - 0s 418us/step - loss: 0.3474 - accuracy: 0.8469\n",
      "Epoch 125/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3529 - accuracy: 0.8409\n",
      "Epoch 126/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3540 - accuracy: 0.8489\n",
      "Epoch 127/500\n",
      "292/292 [==============================] - 0s 476us/step - loss: 0.3592 - accuracy: 0.8412\n",
      "Epoch 128/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3541 - accuracy: 0.8449\n",
      "Epoch 129/500\n",
      "292/292 [==============================] - 0s 419us/step - loss: 0.3562 - accuracy: 0.8446\n",
      "Epoch 130/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3521 - accuracy: 0.8472\n",
      "Epoch 131/500\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.3481 - accuracy: 0.8442\n",
      "Epoch 132/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3583 - accuracy: 0.8426\n",
      "Epoch 133/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3524 - accuracy: 0.8474\n",
      "Epoch 134/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3543 - accuracy: 0.8410\n",
      "Epoch 135/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3515 - accuracy: 0.8446\n",
      "Epoch 136/500\n",
      "292/292 [==============================] - 0s 429us/step - loss: 0.3431 - accuracy: 0.8474\n",
      "Epoch 137/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3429 - accuracy: 0.8482\n",
      "Epoch 138/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3440 - accuracy: 0.8460\n",
      "Epoch 139/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3464 - accuracy: 0.8451\n",
      "Epoch 140/500\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3551 - accuracy: 0.8410\n",
      "\n",
      "Epoch 00140: saving model to checkpoints2/weights.140.hdf5\n",
      "Epoch 141/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3476 - accuracy: 0.8500\n",
      "Epoch 142/500\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3440 - accuracy: 0.8519\n",
      "Epoch 143/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3451 - accuracy: 0.8453\n",
      "Epoch 144/500\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3466 - accuracy: 0.8498\n",
      "Epoch 145/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3458 - accuracy: 0.8471\n",
      "Epoch 146/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3483 - accuracy: 0.8504\n",
      "Epoch 147/500\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.3458 - accuracy: 0.8457\n",
      "Epoch 148/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3369 - accuracy: 0.8538\n",
      "Epoch 149/500\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.3436 - accuracy: 0.8468\n",
      "Epoch 150/500\n",
      "292/292 [==============================] - 0s 389us/step - loss: 0.3466 - accuracy: 0.8454\n",
      "Epoch 151/500\n",
      "292/292 [==============================] - 0s 448us/step - loss: 0.3369 - accuracy: 0.8517\n",
      "Epoch 152/500\n",
      "292/292 [==============================] - 0s 434us/step - loss: 0.3437 - accuracy: 0.8505\n",
      "Epoch 153/500\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.3459 - accuracy: 0.8507\n",
      "Epoch 154/500\n",
      "292/292 [==============================] - 0s 426us/step - loss: 0.3485 - accuracy: 0.8493\n",
      "Epoch 155/500\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3451 - accuracy: 0.8490\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 0s 405us/step - loss: 0.3415 - accuracy: 0.8484\n",
      "Epoch 157/500\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.3393 - accuracy: 0.8530\n",
      "Epoch 158/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3477 - accuracy: 0.8503\n",
      "Epoch 159/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3523 - accuracy: 0.8446\n",
      "Epoch 160/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3411 - accuracy: 0.8440\n",
      "Epoch 161/500\n",
      "292/292 [==============================] - 0s 389us/step - loss: 0.3344 - accuracy: 0.8539\n",
      "Epoch 162/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3414 - accuracy: 0.8480\n",
      "Epoch 163/500\n",
      "292/292 [==============================] - 0s 422us/step - loss: 0.3515 - accuracy: 0.8441\n",
      "Epoch 164/500\n",
      "292/292 [==============================] - 0s 381us/step - loss: 0.3550 - accuracy: 0.8496\n",
      "Epoch 165/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3319 - accuracy: 0.8549\n",
      "Epoch 166/500\n",
      "292/292 [==============================] - 0s 383us/step - loss: 0.3416 - accuracy: 0.8567\n",
      "Epoch 167/500\n",
      "292/292 [==============================] - 0s 386us/step - loss: 0.3394 - accuracy: 0.8508\n",
      "Epoch 168/500\n",
      "292/292 [==============================] - 0s 389us/step - loss: 0.3429 - accuracy: 0.8505\n",
      "Epoch 169/500\n",
      "292/292 [==============================] - 0s 388us/step - loss: 0.3476 - accuracy: 0.8514\n",
      "Epoch 170/500\n",
      "292/292 [==============================] - 0s 386us/step - loss: 0.3376 - accuracy: 0.8525\n",
      "Epoch 171/500\n",
      "292/292 [==============================] - 0s 385us/step - loss: 0.3296 - accuracy: 0.8607\n",
      "Epoch 172/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3403 - accuracy: 0.8495\n",
      "Epoch 173/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3369 - accuracy: 0.8526\n",
      "Epoch 174/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3391 - accuracy: 0.8520\n",
      "Epoch 175/500\n",
      "292/292 [==============================] - 0s 389us/step - loss: 0.3369 - accuracy: 0.8495\n",
      "Epoch 176/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3339 - accuracy: 0.8527\n",
      "Epoch 177/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3423 - accuracy: 0.8528\n",
      "Epoch 178/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3463 - accuracy: 0.8473\n",
      "Epoch 179/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3435 - accuracy: 0.8515\n",
      "Epoch 180/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3507 - accuracy: 0.8446\n",
      "Epoch 181/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3429 - accuracy: 0.8519\n",
      "Epoch 182/500\n",
      "292/292 [==============================] - 0s 387us/step - loss: 0.3306 - accuracy: 0.8541\n",
      "Epoch 183/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3407 - accuracy: 0.8514\n",
      "Epoch 184/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3361 - accuracy: 0.8558\n",
      "Epoch 185/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3412 - accuracy: 0.8502\n",
      "Epoch 186/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3377 - accuracy: 0.8491\n",
      "Epoch 187/500\n",
      "292/292 [==============================] - 0s 389us/step - loss: 0.3384 - accuracy: 0.8520\n",
      "Epoch 188/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3367 - accuracy: 0.8538\n",
      "Epoch 189/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3345 - accuracy: 0.8579\n",
      "Epoch 190/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3529 - accuracy: 0.8450\n",
      "Epoch 191/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3268 - accuracy: 0.8596\n",
      "Epoch 192/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3293 - accuracy: 0.8538\n",
      "Epoch 193/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3247 - accuracy: 0.8570\n",
      "Epoch 194/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3376 - accuracy: 0.8495\n",
      "Epoch 195/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3446 - accuracy: 0.8552\n",
      "Epoch 196/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3383 - accuracy: 0.8524\n",
      "Epoch 197/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3297 - accuracy: 0.8559\n",
      "Epoch 198/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3332 - accuracy: 0.8610\n",
      "Epoch 199/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3410 - accuracy: 0.8454\n",
      "Epoch 200/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3383 - accuracy: 0.8542\n",
      "Epoch 201/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3360 - accuracy: 0.8503\n",
      "Epoch 202/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3444 - accuracy: 0.8503\n",
      "Epoch 203/500\n",
      "292/292 [==============================] - 0s 388us/step - loss: 0.3361 - accuracy: 0.8566\n",
      "Epoch 204/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3320 - accuracy: 0.8553\n",
      "Epoch 205/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3354 - accuracy: 0.8532\n",
      "Epoch 206/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3380 - accuracy: 0.8550\n",
      "Epoch 207/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3406 - accuracy: 0.8517\n",
      "Epoch 208/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3271 - accuracy: 0.8599\n",
      "Epoch 209/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3401 - accuracy: 0.8511\n",
      "Epoch 210/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3267 - accuracy: 0.8512\n",
      "Epoch 211/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3295 - accuracy: 0.8586\n",
      "Epoch 212/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3308 - accuracy: 0.8535\n",
      "Epoch 213/500\n",
      "292/292 [==============================] - 0s 388us/step - loss: 0.3475 - accuracy: 0.8458\n",
      "Epoch 214/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3281 - accuracy: 0.8579\n",
      "Epoch 215/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3349 - accuracy: 0.8529\n",
      "Epoch 216/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3288 - accuracy: 0.8569\n",
      "Epoch 217/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3348 - accuracy: 0.8582\n",
      "Epoch 218/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3259 - accuracy: 0.8550\n",
      "Epoch 219/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3266 - accuracy: 0.8605\n",
      "Epoch 220/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3433 - accuracy: 0.8492\n",
      "Epoch 221/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3326 - accuracy: 0.8549\n",
      "Epoch 222/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3304 - accuracy: 0.8517\n",
      "Epoch 223/500\n",
      "292/292 [==============================] - 0s 437us/step - loss: 0.3361 - accuracy: 0.8552\n",
      "Epoch 224/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3251 - accuracy: 0.8575\n",
      "Epoch 225/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3333 - accuracy: 0.8556\n",
      "Epoch 226/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3216 - accuracy: 0.8605\n",
      "Epoch 227/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3172 - accuracy: 0.8641\n",
      "Epoch 228/500\n",
      "292/292 [==============================] - 0s 433us/step - loss: 0.3262 - accuracy: 0.8611\n",
      "Epoch 229/500\n",
      "292/292 [==============================] - 0s 441us/step - loss: 0.3284 - accuracy: 0.8562\n",
      "Epoch 230/500\n",
      "292/292 [==============================] - 0s 842us/step - loss: 0.3296 - accuracy: 0.8615\n",
      "Epoch 231/500\n",
      "292/292 [==============================] - 0s 577us/step - loss: 0.3265 - accuracy: 0.8647\n",
      "Epoch 232/500\n",
      "292/292 [==============================] - 0s 427us/step - loss: 0.3166 - accuracy: 0.8673\n",
      "Epoch 233/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3279 - accuracy: 0.8580\n",
      "Epoch 234/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3309 - accuracy: 0.8560\n",
      "Epoch 235/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3209 - accuracy: 0.8636\n",
      "Epoch 236/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3255 - accuracy: 0.8602\n",
      "Epoch 237/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3325 - accuracy: 0.8558\n",
      "Epoch 238/500\n",
      "292/292 [==============================] - 0s 388us/step - loss: 0.3298 - accuracy: 0.8568\n",
      "Epoch 239/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3382 - accuracy: 0.8537\n",
      "Epoch 240/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3353 - accuracy: 0.8558\n",
      "\n",
      "Epoch 00240: saving model to checkpoints2/weights.240.hdf5\n",
      "Epoch 241/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3371 - accuracy: 0.8497\n",
      "Epoch 242/500\n",
      "292/292 [==============================] - 0s 389us/step - loss: 0.3196 - accuracy: 0.8594\n",
      "Epoch 243/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3250 - accuracy: 0.8598\n",
      "Epoch 244/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3286 - accuracy: 0.8570\n",
      "Epoch 245/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3295 - accuracy: 0.8574\n",
      "Epoch 246/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3264 - accuracy: 0.8639\n",
      "Epoch 247/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3170 - accuracy: 0.8595\n",
      "Epoch 248/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3342 - accuracy: 0.8557\n",
      "Epoch 249/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3231 - accuracy: 0.8609\n",
      "Epoch 250/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3237 - accuracy: 0.8593\n",
      "Epoch 251/500\n",
      "292/292 [==============================] - 0s 435us/step - loss: 0.3239 - accuracy: 0.8589\n",
      "Epoch 252/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3319 - accuracy: 0.8638\n",
      "Epoch 253/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3195 - accuracy: 0.8645\n",
      "Epoch 254/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3251 - accuracy: 0.8567\n",
      "Epoch 255/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3210 - accuracy: 0.8594\n",
      "Epoch 256/500\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.3302 - accuracy: 0.8554\n",
      "Epoch 257/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3375 - accuracy: 0.8516\n",
      "Epoch 258/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3346 - accuracy: 0.8582\n",
      "Epoch 259/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3317 - accuracy: 0.8601\n",
      "Epoch 260/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3228 - accuracy: 0.8606\n",
      "Epoch 261/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3304 - accuracy: 0.8566\n",
      "Epoch 262/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3241 - accuracy: 0.8615\n",
      "Epoch 263/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3184 - accuracy: 0.8603\n",
      "Epoch 264/500\n",
      "292/292 [==============================] - 0s 427us/step - loss: 0.3218 - accuracy: 0.8585\n",
      "Epoch 265/500\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3259 - accuracy: 0.8566\n",
      "Epoch 266/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3176 - accuracy: 0.8651\n",
      "Epoch 267/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3276 - accuracy: 0.8570\n",
      "Epoch 268/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3398 - accuracy: 0.8574\n",
      "Epoch 269/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3167 - accuracy: 0.8666\n",
      "Epoch 270/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3204 - accuracy: 0.8566\n",
      "Epoch 271/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3479 - accuracy: 0.8532\n",
      "Epoch 272/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3224 - accuracy: 0.8575\n",
      "Epoch 273/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3260 - accuracy: 0.8615\n",
      "Epoch 274/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3198 - accuracy: 0.8651\n",
      "Epoch 275/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3340 - accuracy: 0.8528\n",
      "Epoch 276/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3364 - accuracy: 0.8572\n",
      "Epoch 277/500\n",
      "292/292 [==============================] - 0s 933us/step - loss: 0.3197 - accuracy: 0.8651\n",
      "Epoch 278/500\n",
      "292/292 [==============================] - 0s 435us/step - loss: 0.3186 - accuracy: 0.8642\n",
      "Epoch 279/500\n",
      "292/292 [==============================] - 0s 432us/step - loss: 0.3196 - accuracy: 0.8604\n",
      "Epoch 280/500\n",
      "292/292 [==============================] - 0s 424us/step - loss: 0.3271 - accuracy: 0.8618\n",
      "Epoch 281/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3161 - accuracy: 0.8609\n",
      "Epoch 282/500\n",
      "292/292 [==============================] - 0s 887us/step - loss: 0.3088 - accuracy: 0.8720\n",
      "Epoch 283/500\n",
      "292/292 [==============================] - 0s 424us/step - loss: 0.3221 - accuracy: 0.8604\n",
      "Epoch 284/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3155 - accuracy: 0.8644\n",
      "Epoch 285/500\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.3213 - accuracy: 0.8627\n",
      "Epoch 286/500\n",
      "292/292 [==============================] - 0s 419us/step - loss: 0.3257 - accuracy: 0.8585\n",
      "Epoch 287/500\n",
      "292/292 [==============================] - 0s 873us/step - loss: 0.3250 - accuracy: 0.8600\n",
      "Epoch 288/500\n",
      "292/292 [==============================] - 0s 429us/step - loss: 0.3332 - accuracy: 0.8584\n",
      "Epoch 289/500\n",
      "292/292 [==============================] - 0s 424us/step - loss: 0.3200 - accuracy: 0.8631\n",
      "Epoch 290/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3209 - accuracy: 0.8643\n",
      "Epoch 291/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3340 - accuracy: 0.8574\n",
      "Epoch 292/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3202 - accuracy: 0.8606\n",
      "Epoch 293/500\n",
      "292/292 [==============================] - 0s 430us/step - loss: 0.3304 - accuracy: 0.8592\n",
      "Epoch 294/500\n",
      "292/292 [==============================] - 0s 436us/step - loss: 0.3380 - accuracy: 0.8555\n",
      "Epoch 295/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3038 - accuracy: 0.8715\n",
      "Epoch 296/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3268 - accuracy: 0.8634\n",
      "Epoch 297/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3265 - accuracy: 0.8626\n",
      "Epoch 298/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3204 - accuracy: 0.8622\n",
      "Epoch 299/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3194 - accuracy: 0.8641\n",
      "Epoch 300/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3262 - accuracy: 0.8569\n",
      "Epoch 301/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3165 - accuracy: 0.8705\n",
      "Epoch 302/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3224 - accuracy: 0.8583\n",
      "Epoch 303/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3172 - accuracy: 0.8649\n",
      "Epoch 304/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3178 - accuracy: 0.8660\n",
      "Epoch 305/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3112 - accuracy: 0.8624\n",
      "Epoch 306/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3256 - accuracy: 0.8593\n",
      "Epoch 307/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3106 - accuracy: 0.8690\n",
      "Epoch 308/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3245 - accuracy: 0.8590\n",
      "Epoch 309/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3201 - accuracy: 0.8615\n",
      "Epoch 310/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3226 - accuracy: 0.8619\n",
      "Epoch 311/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 0s 401us/step - loss: 0.3196 - accuracy: 0.8640\n",
      "Epoch 312/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3249 - accuracy: 0.8602\n",
      "Epoch 313/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3141 - accuracy: 0.8649\n",
      "Epoch 314/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3174 - accuracy: 0.8614\n",
      "Epoch 315/500\n",
      "292/292 [==============================] - 0s 387us/step - loss: 0.3134 - accuracy: 0.8644\n",
      "Epoch 316/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3148 - accuracy: 0.8605\n",
      "Epoch 317/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3176 - accuracy: 0.8652\n",
      "Epoch 318/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3179 - accuracy: 0.8631\n",
      "Epoch 319/500\n",
      "292/292 [==============================] - 0s 389us/step - loss: 0.3213 - accuracy: 0.8619\n",
      "Epoch 320/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3163 - accuracy: 0.8605\n",
      "Epoch 321/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3179 - accuracy: 0.8650\n",
      "Epoch 322/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3203 - accuracy: 0.8582\n",
      "Epoch 323/500\n",
      "292/292 [==============================] - 0s 390us/step - loss: 0.3176 - accuracy: 0.8614\n",
      "Epoch 324/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3180 - accuracy: 0.8630\n",
      "Epoch 325/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3108 - accuracy: 0.8742\n",
      "Epoch 326/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3234 - accuracy: 0.8642\n",
      "Epoch 327/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3191 - accuracy: 0.8643\n",
      "Epoch 328/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3186 - accuracy: 0.8635\n",
      "Epoch 329/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3255 - accuracy: 0.8564\n",
      "Epoch 330/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3272 - accuracy: 0.8542\n",
      "Epoch 331/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3216 - accuracy: 0.8640\n",
      "Epoch 332/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3197 - accuracy: 0.8613\n",
      "Epoch 333/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3249 - accuracy: 0.8592\n",
      "Epoch 334/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3151 - accuracy: 0.8587\n",
      "Epoch 335/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3163 - accuracy: 0.8633\n",
      "Epoch 336/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3138 - accuracy: 0.8646\n",
      "Epoch 337/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3156 - accuracy: 0.8630\n",
      "Epoch 338/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3197 - accuracy: 0.8667\n",
      "Epoch 339/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3100 - accuracy: 0.8694\n",
      "Epoch 340/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3111 - accuracy: 0.8646\n",
      "\n",
      "Epoch 00340: saving model to checkpoints2/weights.340.hdf5\n",
      "Epoch 341/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3180 - accuracy: 0.8611\n",
      "Epoch 342/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3147 - accuracy: 0.8644\n",
      "Epoch 343/500\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3396 - accuracy: 0.8523\n",
      "Epoch 344/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3136 - accuracy: 0.8654\n",
      "Epoch 345/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3155 - accuracy: 0.8662\n",
      "Epoch 346/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3098 - accuracy: 0.8697\n",
      "Epoch 347/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3143 - accuracy: 0.8647\n",
      "Epoch 348/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3202 - accuracy: 0.8595\n",
      "Epoch 349/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3209 - accuracy: 0.8626\n",
      "Epoch 350/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3285 - accuracy: 0.8597\n",
      "Epoch 351/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3089 - accuracy: 0.8665\n",
      "Epoch 352/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3219 - accuracy: 0.8625\n",
      "Epoch 353/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3138 - accuracy: 0.8690\n",
      "Epoch 354/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3284 - accuracy: 0.8597\n",
      "Epoch 355/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3172 - accuracy: 0.8639\n",
      "Epoch 356/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3108 - accuracy: 0.8652\n",
      "Epoch 357/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3149 - accuracy: 0.8697\n",
      "Epoch 358/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3237 - accuracy: 0.8612\n",
      "Epoch 359/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3171 - accuracy: 0.8670\n",
      "Epoch 360/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3038 - accuracy: 0.8697\n",
      "Epoch 361/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3161 - accuracy: 0.8608\n",
      "Epoch 362/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3107 - accuracy: 0.8698\n",
      "Epoch 363/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3304 - accuracy: 0.8580\n",
      "Epoch 364/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3159 - accuracy: 0.8635\n",
      "Epoch 365/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3107 - accuracy: 0.8650\n",
      "Epoch 366/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3142 - accuracy: 0.8630\n",
      "Epoch 367/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3322 - accuracy: 0.8573\n",
      "Epoch 368/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3160 - accuracy: 0.8623\n",
      "Epoch 369/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3195 - accuracy: 0.8667\n",
      "Epoch 370/500\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.3232 - accuracy: 0.8593\n",
      "Epoch 371/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3252 - accuracy: 0.8571\n",
      "Epoch 372/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3221 - accuracy: 0.8613\n",
      "Epoch 373/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3311 - accuracy: 0.8601\n",
      "Epoch 374/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3125 - accuracy: 0.8636\n",
      "Epoch 375/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3196 - accuracy: 0.8588\n",
      "Epoch 376/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3180 - accuracy: 0.8624\n",
      "Epoch 377/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3172 - accuracy: 0.8648\n",
      "Epoch 378/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3145 - accuracy: 0.8642\n",
      "Epoch 379/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3187 - accuracy: 0.8631\n",
      "Epoch 380/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3157 - accuracy: 0.8611\n",
      "Epoch 381/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3176 - accuracy: 0.8668\n",
      "Epoch 382/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3164 - accuracy: 0.8628\n",
      "Epoch 383/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3152 - accuracy: 0.8640\n",
      "Epoch 384/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3132 - accuracy: 0.8651\n",
      "Epoch 385/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3150 - accuracy: 0.8677\n",
      "Epoch 386/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3029 - accuracy: 0.8696\n",
      "Epoch 387/500\n",
      "292/292 [==============================] - 0s 434us/step - loss: 0.3124 - accuracy: 0.8647\n",
      "Epoch 388/500\n",
      "292/292 [==============================] - 0s 443us/step - loss: 0.3180 - accuracy: 0.8616\n",
      "Epoch 389/500\n",
      "292/292 [==============================] - 0s 438us/step - loss: 0.3214 - accuracy: 0.8626\n",
      "Epoch 390/500\n",
      "292/292 [==============================] - 0s 430us/step - loss: 0.3169 - accuracy: 0.8657\n",
      "Epoch 391/500\n",
      "292/292 [==============================] - 0s 400us/step - loss: 0.3222 - accuracy: 0.8590\n",
      "Epoch 392/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3167 - accuracy: 0.8631\n",
      "Epoch 393/500\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3180 - accuracy: 0.8628\n",
      "Epoch 394/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3047 - accuracy: 0.8735\n",
      "Epoch 395/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3155 - accuracy: 0.8629\n",
      "Epoch 396/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3125 - accuracy: 0.8671\n",
      "Epoch 397/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3095 - accuracy: 0.8657\n",
      "Epoch 398/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3114 - accuracy: 0.8607\n",
      "Epoch 399/500\n",
      "292/292 [==============================] - 0s 385us/step - loss: 0.3197 - accuracy: 0.8608\n",
      "Epoch 400/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3279 - accuracy: 0.8614\n",
      "Epoch 401/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3111 - accuracy: 0.8671\n",
      "Epoch 402/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3112 - accuracy: 0.8657\n",
      "Epoch 403/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3205 - accuracy: 0.8620\n",
      "Epoch 404/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3206 - accuracy: 0.8596\n",
      "Epoch 405/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3123 - accuracy: 0.8687\n",
      "Epoch 406/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3118 - accuracy: 0.8677\n",
      "Epoch 407/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3070 - accuracy: 0.8671\n",
      "Epoch 408/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3256 - accuracy: 0.8532\n",
      "Epoch 409/500\n",
      "292/292 [==============================] - 0s 500us/step - loss: 0.3157 - accuracy: 0.8626\n",
      "Epoch 410/500\n",
      "292/292 [==============================] - 0s 779us/step - loss: 0.3143 - accuracy: 0.8684\n",
      "Epoch 411/500\n",
      "292/292 [==============================] - 0s 476us/step - loss: 0.3163 - accuracy: 0.8653\n",
      "Epoch 412/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3161 - accuracy: 0.8632\n",
      "Epoch 413/500\n",
      "292/292 [==============================] - 0s 405us/step - loss: 0.3106 - accuracy: 0.8660\n",
      "Epoch 414/500\n",
      "292/292 [==============================] - 0s 397us/step - loss: 0.3027 - accuracy: 0.8655\n",
      "Epoch 415/500\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3300 - accuracy: 0.8646\n",
      "Epoch 416/500\n",
      "292/292 [==============================] - 0s 456us/step - loss: 0.3075 - accuracy: 0.8697\n",
      "Epoch 417/500\n",
      "292/292 [==============================] - 0s 771us/step - loss: 0.3101 - accuracy: 0.8675\n",
      "Epoch 418/500\n",
      "292/292 [==============================] - 0s 450us/step - loss: 0.3182 - accuracy: 0.8609\n",
      "Epoch 419/500\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3198 - accuracy: 0.8613\n",
      "Epoch 420/500\n",
      "292/292 [==============================] - 0s 383us/step - loss: 0.3195 - accuracy: 0.8631\n",
      "Epoch 421/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3100 - accuracy: 0.8689\n",
      "Epoch 422/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3204 - accuracy: 0.8608\n",
      "Epoch 423/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3049 - accuracy: 0.8715\n",
      "Epoch 424/500\n",
      "292/292 [==============================] - 0s 392us/step - loss: 0.3117 - accuracy: 0.8657\n",
      "Epoch 425/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3148 - accuracy: 0.8681\n",
      "Epoch 426/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3122 - accuracy: 0.8695\n",
      "Epoch 427/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3216 - accuracy: 0.8619\n",
      "Epoch 428/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3103 - accuracy: 0.8687\n",
      "Epoch 429/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3174 - accuracy: 0.8680\n",
      "Epoch 430/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3254 - accuracy: 0.8626\n",
      "Epoch 431/500\n",
      "292/292 [==============================] - 0s 393us/step - loss: 0.3039 - accuracy: 0.8698\n",
      "Epoch 432/500\n",
      "292/292 [==============================] - 0s 391us/step - loss: 0.3140 - accuracy: 0.8640\n",
      "Epoch 433/500\n",
      "292/292 [==============================] - 0s 395us/step - loss: 0.3074 - accuracy: 0.8669\n",
      "Epoch 434/500\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.3137 - accuracy: 0.8674\n",
      "Epoch 435/500\n",
      "292/292 [==============================] - 0s 442us/step - loss: 0.3106 - accuracy: 0.8689\n",
      "Epoch 436/500\n",
      "292/292 [==============================] - 0s 420us/step - loss: 0.3167 - accuracy: 0.8648\n",
      "Epoch 437/500\n",
      "292/292 [==============================] - 0s 434us/step - loss: 0.3143 - accuracy: 0.8677\n",
      "Epoch 438/500\n",
      "292/292 [==============================] - 0s 441us/step - loss: 0.3100 - accuracy: 0.8677\n",
      "Epoch 439/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3095 - accuracy: 0.8698\n",
      "Epoch 440/500\n",
      "292/292 [==============================] - 0s 398us/step - loss: 0.3086 - accuracy: 0.8640\n",
      "\n",
      "Epoch 00440: saving model to checkpoints2/weights.440.hdf5\n",
      "Epoch 441/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3115 - accuracy: 0.8728\n",
      "Epoch 442/500\n",
      "292/292 [==============================] - 0s 549us/step - loss: 0.3153 - accuracy: 0.8663\n",
      "Epoch 443/500\n",
      "292/292 [==============================] - 0s 437us/step - loss: 0.3211 - accuracy: 0.8645\n",
      "Epoch 444/500\n",
      "292/292 [==============================] - 0s 458us/step - loss: 0.3170 - accuracy: 0.8643\n",
      "Epoch 445/500\n",
      "292/292 [==============================] - 0s 458us/step - loss: 0.3157 - accuracy: 0.8650\n",
      "Epoch 446/500\n",
      "292/292 [==============================] - 0s 426us/step - loss: 0.3041 - accuracy: 0.8726\n",
      "Epoch 447/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3129 - accuracy: 0.8696\n",
      "Epoch 448/500\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.3228 - accuracy: 0.8637\n",
      "Epoch 449/500\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.3118 - accuracy: 0.8703\n",
      "Epoch 450/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3168 - accuracy: 0.8660\n",
      "Epoch 451/500\n",
      "292/292 [==============================] - 0s 418us/step - loss: 0.3170 - accuracy: 0.8642\n",
      "Epoch 452/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3133 - accuracy: 0.8669\n",
      "Epoch 453/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3116 - accuracy: 0.8649\n",
      "Epoch 454/500\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3145 - accuracy: 0.8646\n",
      "Epoch 455/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3107 - accuracy: 0.8700\n",
      "Epoch 456/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3194 - accuracy: 0.8660\n",
      "Epoch 457/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3131 - accuracy: 0.8680\n",
      "Epoch 458/500\n",
      "292/292 [==============================] - 0s 428us/step - loss: 0.3115 - accuracy: 0.8674\n",
      "Epoch 459/500\n",
      "292/292 [==============================] - 0s 426us/step - loss: 0.3114 - accuracy: 0.8695\n",
      "Epoch 460/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3061 - accuracy: 0.8680\n",
      "Epoch 461/500\n",
      "292/292 [==============================] - 0s 411us/step - loss: 0.3063 - accuracy: 0.8693\n",
      "Epoch 462/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3150 - accuracy: 0.8688\n",
      "Epoch 463/500\n",
      "292/292 [==============================] - 0s 416us/step - loss: 0.3174 - accuracy: 0.8684\n",
      "Epoch 464/500\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.3055 - accuracy: 0.8689\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292/292 [==============================] - 0s 416us/step - loss: 0.3053 - accuracy: 0.8721\n",
      "Epoch 466/500\n",
      "292/292 [==============================] - 0s 415us/step - loss: 0.3173 - accuracy: 0.8636\n",
      "Epoch 467/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3075 - accuracy: 0.8700\n",
      "Epoch 468/500\n",
      "292/292 [==============================] - 0s 402us/step - loss: 0.3133 - accuracy: 0.8678\n",
      "Epoch 469/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3091 - accuracy: 0.8638\n",
      "Epoch 470/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3025 - accuracy: 0.8692\n",
      "Epoch 471/500\n",
      "292/292 [==============================] - 0s 396us/step - loss: 0.3235 - accuracy: 0.8619\n",
      "Epoch 472/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3119 - accuracy: 0.8663\n",
      "Epoch 473/500\n",
      "292/292 [==============================] - 0s 394us/step - loss: 0.3175 - accuracy: 0.8665\n",
      "Epoch 474/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3112 - accuracy: 0.8677\n",
      "Epoch 475/500\n",
      "292/292 [==============================] - 0s 399us/step - loss: 0.3103 - accuracy: 0.8651\n",
      "Epoch 476/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3211 - accuracy: 0.8636\n",
      "Epoch 477/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3103 - accuracy: 0.8705\n",
      "Epoch 478/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3171 - accuracy: 0.8660\n",
      "Epoch 479/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3067 - accuracy: 0.8694\n",
      "Epoch 480/500\n",
      "292/292 [==============================] - 0s 416us/step - loss: 0.3047 - accuracy: 0.8715\n",
      "Epoch 481/500\n",
      "292/292 [==============================] - 0s 410us/step - loss: 0.3099 - accuracy: 0.8725\n",
      "Epoch 482/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3111 - accuracy: 0.8630\n",
      "Epoch 483/500\n",
      "292/292 [==============================] - 0s 407us/step - loss: 0.3049 - accuracy: 0.8686\n",
      "Epoch 484/500\n",
      "292/292 [==============================] - 0s 412us/step - loss: 0.2995 - accuracy: 0.8771\n",
      "Epoch 485/500\n",
      "292/292 [==============================] - 0s 418us/step - loss: 0.3138 - accuracy: 0.8680\n",
      "Epoch 486/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3004 - accuracy: 0.8734\n",
      "Epoch 487/500\n",
      "292/292 [==============================] - 0s 414us/step - loss: 0.3056 - accuracy: 0.8655\n",
      "Epoch 488/500\n",
      "292/292 [==============================] - 0s 419us/step - loss: 0.3082 - accuracy: 0.8650\n",
      "Epoch 489/500\n",
      "292/292 [==============================] - 0s 401us/step - loss: 0.3192 - accuracy: 0.8620\n",
      "Epoch 490/500\n",
      "292/292 [==============================] - 0s 424us/step - loss: 0.3067 - accuracy: 0.8691\n",
      "Epoch 491/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3136 - accuracy: 0.8689\n",
      "Epoch 492/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.2988 - accuracy: 0.8742\n",
      "Epoch 493/500\n",
      "292/292 [==============================] - 0s 408us/step - loss: 0.3195 - accuracy: 0.8634\n",
      "Epoch 494/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3140 - accuracy: 0.8672\n",
      "Epoch 495/500\n",
      "292/292 [==============================] - 0s 409us/step - loss: 0.3037 - accuracy: 0.8720\n",
      "Epoch 496/500\n",
      "292/292 [==============================] - 0s 404us/step - loss: 0.3011 - accuracy: 0.8735\n",
      "Epoch 497/500\n",
      "292/292 [==============================] - 0s 406us/step - loss: 0.3144 - accuracy: 0.8647\n",
      "Epoch 498/500\n",
      "292/292 [==============================] - 0s 413us/step - loss: 0.2984 - accuracy: 0.8722\n",
      "Epoch 499/500\n",
      "292/292 [==============================] - 0s 427us/step - loss: 0.3033 - accuracy: 0.8717\n",
      "Epoch 500/500\n",
      "292/292 [==============================] - 0s 403us/step - loss: 0.3166 - accuracy: 0.8625\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=500,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c6fbe318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 318us/step - loss: 0.4833 - accuracy: 0.8145\n",
      "Loss: 0.4832592308521271, Accuracy: 0.8144927620887756\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model with our test data\n",
    "\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "18801942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"relu28_relu14_sigmoid_a81.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "805e36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a checkpoint save\n",
    "\n",
    "os.makedirs(\"checkpoints2/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints2/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "527c994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights every epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fc37d229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>genre_1_Electronic</th>\n",
       "      <th>genre_1_Indie</th>\n",
       "      <th>genre_1_Latin</th>\n",
       "      <th>genre_1_Other</th>\n",
       "      <th>genre_1_Pop</th>\n",
       "      <th>genre_1_Rap</th>\n",
       "      <th>genre_1_Rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176532</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.415339</td>\n",
       "      <td>0.235930</td>\n",
       "      <td>-0.251642</td>\n",
       "      <td>-0.288158</td>\n",
       "      <td>-0.126325</td>\n",
       "      <td>0.510802</td>\n",
       "      <td>-0.127074</td>\n",
       "      <td>-0.193440</td>\n",
       "      <td>0.074486</td>\n",
       "      <td>-0.024333</td>\n",
       "      <td>0.286851</td>\n",
       "      <td>-0.325269</td>\n",
       "      <td>0.169759</td>\n",
       "      <td>0.227087</td>\n",
       "      <td>-0.210563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>0.176532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.739625</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>-0.747068</td>\n",
       "      <td>-0.310891</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>0.355497</td>\n",
       "      <td>0.160893</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.129381</td>\n",
       "      <td>-0.022046</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>-0.267266</td>\n",
       "      <td>0.028810</td>\n",
       "      <td>-0.021973</td>\n",
       "      <td>0.226736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>0.031393</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.024396</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>-0.027506</td>\n",
       "      <td>-0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>0.415339</td>\n",
       "      <td>0.739625</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131648</td>\n",
       "      <td>-0.648365</td>\n",
       "      <td>-0.612246</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>0.377848</td>\n",
       "      <td>0.173238</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.168824</td>\n",
       "      <td>-0.361038</td>\n",
       "      <td>0.127179</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.146590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>0.235930</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.131648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.124657</td>\n",
       "      <td>-0.162790</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.077043</td>\n",
       "      <td>0.156775</td>\n",
       "      <td>-0.156123</td>\n",
       "      <td>-0.056367</td>\n",
       "      <td>-0.088949</td>\n",
       "      <td>0.105524</td>\n",
       "      <td>-0.136770</td>\n",
       "      <td>-0.021182</td>\n",
       "      <td>0.417082</td>\n",
       "      <td>-0.055853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>-0.251642</td>\n",
       "      <td>-0.747068</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>-0.648365</td>\n",
       "      <td>-0.124657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336851</td>\n",
       "      <td>-0.142544</td>\n",
       "      <td>-0.258376</td>\n",
       "      <td>-0.144581</td>\n",
       "      <td>-0.009809</td>\n",
       "      <td>-0.103890</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>-0.056691</td>\n",
       "      <td>0.285380</td>\n",
       "      <td>-0.037802</td>\n",
       "      <td>-0.111507</td>\n",
       "      <td>-0.189015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>-0.288158</td>\n",
       "      <td>-0.310891</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.612246</td>\n",
       "      <td>-0.162790</td>\n",
       "      <td>0.336851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.227825</td>\n",
       "      <td>-0.125884</td>\n",
       "      <td>0.067407</td>\n",
       "      <td>0.214549</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>-0.134329</td>\n",
       "      <td>0.252617</td>\n",
       "      <td>-0.196511</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>-0.095048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>-0.126325</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>-0.142544</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013796</td>\n",
       "      <td>0.047190</td>\n",
       "      <td>-0.049888</td>\n",
       "      <td>-0.015061</td>\n",
       "      <td>-0.014613</td>\n",
       "      <td>-0.082027</td>\n",
       "      <td>-0.002297</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>0.077605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.510802</td>\n",
       "      <td>0.355497</td>\n",
       "      <td>0.031393</td>\n",
       "      <td>0.377848</td>\n",
       "      <td>0.077043</td>\n",
       "      <td>-0.258376</td>\n",
       "      <td>-0.227825</td>\n",
       "      <td>-0.013796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>-0.149176</td>\n",
       "      <td>-0.048087</td>\n",
       "      <td>-0.012854</td>\n",
       "      <td>0.128988</td>\n",
       "      <td>-0.134380</td>\n",
       "      <td>0.109694</td>\n",
       "      <td>-0.029970</td>\n",
       "      <td>0.014566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>-0.127074</td>\n",
       "      <td>0.160893</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.173238</td>\n",
       "      <td>0.156775</td>\n",
       "      <td>-0.144581</td>\n",
       "      <td>-0.125884</td>\n",
       "      <td>0.047190</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008479</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>-0.061773</td>\n",
       "      <td>-0.120796</td>\n",
       "      <td>0.045110</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>0.098480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms</th>\n",
       "      <td>-0.193440</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>-0.156123</td>\n",
       "      <td>-0.009809</td>\n",
       "      <td>0.067407</td>\n",
       "      <td>-0.049888</td>\n",
       "      <td>-0.149176</td>\n",
       "      <td>-0.008479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>-0.030544</td>\n",
       "      <td>0.153090</td>\n",
       "      <td>-0.153208</td>\n",
       "      <td>-0.104079</td>\n",
       "      <td>0.032853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Electronic</th>\n",
       "      <td>0.074486</td>\n",
       "      <td>0.129381</td>\n",
       "      <td>0.024396</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>-0.056367</td>\n",
       "      <td>-0.103890</td>\n",
       "      <td>0.214549</td>\n",
       "      <td>-0.015061</td>\n",
       "      <td>-0.048087</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092309</td>\n",
       "      <td>-0.086467</td>\n",
       "      <td>-0.196084</td>\n",
       "      <td>-0.142833</td>\n",
       "      <td>-0.070610</td>\n",
       "      <td>-0.094482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Indie</th>\n",
       "      <td>-0.024333</td>\n",
       "      <td>-0.022046</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>-0.088949</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>-0.014613</td>\n",
       "      <td>-0.012854</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>-0.092309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109048</td>\n",
       "      <td>-0.247291</td>\n",
       "      <td>-0.180133</td>\n",
       "      <td>-0.089050</td>\n",
       "      <td>-0.119156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Latin</th>\n",
       "      <td>0.286851</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.168824</td>\n",
       "      <td>0.105524</td>\n",
       "      <td>-0.056691</td>\n",
       "      <td>-0.134329</td>\n",
       "      <td>-0.082027</td>\n",
       "      <td>0.128988</td>\n",
       "      <td>-0.061773</td>\n",
       "      <td>-0.030544</td>\n",
       "      <td>-0.086467</td>\n",
       "      <td>-0.109048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.231643</td>\n",
       "      <td>-0.168735</td>\n",
       "      <td>-0.083415</td>\n",
       "      <td>-0.111616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Other</th>\n",
       "      <td>-0.325269</td>\n",
       "      <td>-0.267266</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>-0.361038</td>\n",
       "      <td>-0.136770</td>\n",
       "      <td>0.285380</td>\n",
       "      <td>0.252617</td>\n",
       "      <td>-0.002297</td>\n",
       "      <td>-0.134380</td>\n",
       "      <td>-0.120796</td>\n",
       "      <td>0.153090</td>\n",
       "      <td>-0.196084</td>\n",
       "      <td>-0.247291</td>\n",
       "      <td>-0.231643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.382643</td>\n",
       "      <td>-0.189162</td>\n",
       "      <td>-0.253114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Pop</th>\n",
       "      <td>0.169759</td>\n",
       "      <td>0.028810</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.127179</td>\n",
       "      <td>-0.021182</td>\n",
       "      <td>-0.037802</td>\n",
       "      <td>-0.196511</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.109694</td>\n",
       "      <td>0.045110</td>\n",
       "      <td>-0.153208</td>\n",
       "      <td>-0.142833</td>\n",
       "      <td>-0.180133</td>\n",
       "      <td>-0.168735</td>\n",
       "      <td>-0.382643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.137790</td>\n",
       "      <td>-0.184375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Rap</th>\n",
       "      <td>0.227087</td>\n",
       "      <td>-0.021973</td>\n",
       "      <td>-0.027506</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.417082</td>\n",
       "      <td>-0.111507</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>-0.029970</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>-0.104079</td>\n",
       "      <td>-0.070610</td>\n",
       "      <td>-0.089050</td>\n",
       "      <td>-0.083415</td>\n",
       "      <td>-0.189162</td>\n",
       "      <td>-0.137790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Rock</th>\n",
       "      <td>-0.210563</td>\n",
       "      <td>0.226736</td>\n",
       "      <td>-0.003631</td>\n",
       "      <td>0.146590</td>\n",
       "      <td>-0.055853</td>\n",
       "      <td>-0.189015</td>\n",
       "      <td>-0.095048</td>\n",
       "      <td>0.077605</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.098480</td>\n",
       "      <td>0.032853</td>\n",
       "      <td>-0.094482</td>\n",
       "      <td>-0.119156</td>\n",
       "      <td>-0.111616</td>\n",
       "      <td>-0.253114</td>\n",
       "      <td>-0.184375</td>\n",
       "      <td>-0.091147</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    danceability    energy       key  loudness  speechiness  \\\n",
       "danceability            1.000000  0.176532  0.007976  0.415339     0.235930   \n",
       "energy                  0.176532  1.000000  0.027639  0.739625     0.082852   \n",
       "key                     0.007976  0.027639  1.000000  0.023950    -0.001589   \n",
       "loudness                0.415339  0.739625  0.023950  1.000000     0.131648   \n",
       "speechiness             0.235930  0.082852 -0.001589  0.131648     1.000000   \n",
       "acousticness           -0.251642 -0.747068  0.015128 -0.648365    -0.124657   \n",
       "instrumentalness       -0.288158 -0.310891 -0.002144 -0.612246    -0.162790   \n",
       "liveness               -0.126325  0.224275 -0.025700  0.060699     0.024113   \n",
       "valence                 0.510802  0.355497  0.031393  0.377848     0.077043   \n",
       "tempo                  -0.127074  0.160893  0.014039  0.173238     0.156775   \n",
       "duration_ms            -0.193440  0.024106  0.007507  0.003117    -0.156123   \n",
       "genre_1_Electronic      0.074486  0.129381  0.024396  0.042626    -0.056367   \n",
       "genre_1_Indie          -0.024333 -0.022046  0.002311  0.000524    -0.088949   \n",
       "genre_1_Latin           0.286851  0.082822  0.003915  0.168824     0.105524   \n",
       "genre_1_Other          -0.325269 -0.267266 -0.002136 -0.361038    -0.136770   \n",
       "genre_1_Pop             0.169759  0.028810  0.002118  0.127179    -0.021182   \n",
       "genre_1_Rap             0.227087 -0.021973 -0.027506  0.055474     0.417082   \n",
       "genre_1_Rock           -0.210563  0.226736 -0.003631  0.146590    -0.055853   \n",
       "\n",
       "                    acousticness  instrumentalness  liveness   valence  \\\n",
       "danceability           -0.251642         -0.288158 -0.126325  0.510802   \n",
       "energy                 -0.747068         -0.310891  0.224275  0.355497   \n",
       "key                     0.015128         -0.002144 -0.025700  0.031393   \n",
       "loudness               -0.648365         -0.612246  0.060699  0.377848   \n",
       "speechiness            -0.124657         -0.162790  0.024113  0.077043   \n",
       "acousticness            1.000000          0.336851 -0.142544 -0.258376   \n",
       "instrumentalness        0.336851          1.000000 -0.016370 -0.227825   \n",
       "liveness               -0.142544         -0.016370  1.000000 -0.013796   \n",
       "valence                -0.258376         -0.227825 -0.013796  1.000000   \n",
       "tempo                  -0.144581         -0.125884  0.047190  0.054557   \n",
       "duration_ms            -0.009809          0.067407 -0.049888 -0.149176   \n",
       "genre_1_Electronic     -0.103890          0.214549 -0.015061 -0.048087   \n",
       "genre_1_Indie           0.028512          0.012641 -0.014613 -0.012854   \n",
       "genre_1_Latin          -0.056691         -0.134329 -0.082027  0.128988   \n",
       "genre_1_Other           0.285380          0.252617 -0.002297 -0.134380   \n",
       "genre_1_Pop            -0.037802         -0.196511  0.009079  0.109694   \n",
       "genre_1_Rap            -0.111507         -0.115875  0.021431 -0.029970   \n",
       "genre_1_Rock           -0.189015         -0.095048  0.077605  0.014566   \n",
       "\n",
       "                       tempo  duration_ms  genre_1_Electronic  genre_1_Indie  \\\n",
       "danceability       -0.127074    -0.193440            0.074486      -0.024333   \n",
       "energy              0.160893     0.024106            0.129381      -0.022046   \n",
       "key                 0.014039     0.007507            0.024396       0.002311   \n",
       "loudness            0.173238     0.003117            0.042626       0.000524   \n",
       "speechiness         0.156775    -0.156123           -0.056367      -0.088949   \n",
       "acousticness       -0.144581    -0.009809           -0.103890       0.028512   \n",
       "instrumentalness   -0.125884     0.067407            0.214549       0.012641   \n",
       "liveness            0.047190    -0.049888           -0.015061      -0.014613   \n",
       "valence             0.054557    -0.149176           -0.048087      -0.012854   \n",
       "tempo               1.000000    -0.008479            0.010417       0.015359   \n",
       "duration_ms        -0.008479     1.000000            0.056001       0.001493   \n",
       "genre_1_Electronic  0.010417     0.056001            1.000000      -0.092309   \n",
       "genre_1_Indie       0.015359     0.001493           -0.092309       1.000000   \n",
       "genre_1_Latin      -0.061773    -0.030544           -0.086467      -0.109048   \n",
       "genre_1_Other      -0.120796     0.153090           -0.196084      -0.247291   \n",
       "genre_1_Pop         0.045110    -0.153208           -0.142833      -0.180133   \n",
       "genre_1_Rap         0.076585    -0.104079           -0.070610      -0.089050   \n",
       "genre_1_Rock        0.098480     0.032853           -0.094482      -0.119156   \n",
       "\n",
       "                    genre_1_Latin  genre_1_Other  genre_1_Pop  genre_1_Rap  \\\n",
       "danceability             0.286851      -0.325269     0.169759     0.227087   \n",
       "energy                   0.082822      -0.267266     0.028810    -0.021973   \n",
       "key                      0.003915      -0.002136     0.002118    -0.027506   \n",
       "loudness                 0.168824      -0.361038     0.127179     0.055474   \n",
       "speechiness              0.105524      -0.136770    -0.021182     0.417082   \n",
       "acousticness            -0.056691       0.285380    -0.037802    -0.111507   \n",
       "instrumentalness        -0.134329       0.252617    -0.196511    -0.115875   \n",
       "liveness                -0.082027      -0.002297     0.009079     0.021431   \n",
       "valence                  0.128988      -0.134380     0.109694    -0.029970   \n",
       "tempo                   -0.061773      -0.120796     0.045110     0.076585   \n",
       "duration_ms             -0.030544       0.153090    -0.153208    -0.104079   \n",
       "genre_1_Electronic      -0.086467      -0.196084    -0.142833    -0.070610   \n",
       "genre_1_Indie           -0.109048      -0.247291    -0.180133    -0.089050   \n",
       "genre_1_Latin            1.000000      -0.231643    -0.168735    -0.083415   \n",
       "genre_1_Other           -0.231643       1.000000    -0.382643    -0.189162   \n",
       "genre_1_Pop             -0.168735      -0.382643     1.000000    -0.137790   \n",
       "genre_1_Rap             -0.083415      -0.189162    -0.137790     1.000000   \n",
       "genre_1_Rock            -0.111616      -0.253114    -0.184375    -0.091147   \n",
       "\n",
       "                    genre_1_Rock  \n",
       "danceability           -0.210563  \n",
       "energy                  0.226736  \n",
       "key                    -0.003631  \n",
       "loudness                0.146590  \n",
       "speechiness            -0.055853  \n",
       "acousticness           -0.189015  \n",
       "instrumentalness       -0.095048  \n",
       "liveness                0.077605  \n",
       "valence                 0.014566  \n",
       "tempo                   0.098480  \n",
       "duration_ms             0.032853  \n",
       "genre_1_Electronic     -0.094482  \n",
       "genre_1_Indie          -0.119156  \n",
       "genre_1_Latin          -0.111616  \n",
       "genre_1_Other          -0.253114  \n",
       "genre_1_Pop            -0.184375  \n",
       "genre_1_Rap            -0.091147  \n",
       "genre_1_Rock            1.000000  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ff11b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAIN = pd.DataFrame(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "08a722a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>popularity</th>\n",
       "      <th>popular</th>\n",
       "      <th>genre_1_Electronic</th>\n",
       "      <th>genre_1_Indie</th>\n",
       "      <th>genre_1_Latin</th>\n",
       "      <th>genre_1_Other</th>\n",
       "      <th>genre_1_Pop</th>\n",
       "      <th>genre_1_Rap</th>\n",
       "      <th>genre_1_Rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176532</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.415339</td>\n",
       "      <td>0.235930</td>\n",
       "      <td>-0.251642</td>\n",
       "      <td>-0.288158</td>\n",
       "      <td>-0.126325</td>\n",
       "      <td>0.510802</td>\n",
       "      <td>-0.127074</td>\n",
       "      <td>-0.193440</td>\n",
       "      <td>0.304426</td>\n",
       "      <td>0.240245</td>\n",
       "      <td>0.074486</td>\n",
       "      <td>-0.024333</td>\n",
       "      <td>0.286851</td>\n",
       "      <td>-0.325269</td>\n",
       "      <td>0.169759</td>\n",
       "      <td>0.227087</td>\n",
       "      <td>-0.210563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>0.176532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.739625</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>-0.747068</td>\n",
       "      <td>-0.310891</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>0.355497</td>\n",
       "      <td>0.160893</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.108204</td>\n",
       "      <td>0.106622</td>\n",
       "      <td>0.129381</td>\n",
       "      <td>-0.022046</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>-0.267266</td>\n",
       "      <td>0.028810</td>\n",
       "      <td>-0.021973</td>\n",
       "      <td>0.226736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>0.031393</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>-0.001134</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>0.024396</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>-0.027506</td>\n",
       "      <td>-0.003631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness</th>\n",
       "      <td>0.415339</td>\n",
       "      <td>0.739625</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131648</td>\n",
       "      <td>-0.648365</td>\n",
       "      <td>-0.612246</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>0.377848</td>\n",
       "      <td>0.173238</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.202291</td>\n",
       "      <td>0.172487</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.168824</td>\n",
       "      <td>-0.361038</td>\n",
       "      <td>0.127179</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.146590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>0.235930</td>\n",
       "      <td>0.082852</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.131648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.124657</td>\n",
       "      <td>-0.162790</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.077043</td>\n",
       "      <td>0.156775</td>\n",
       "      <td>-0.156123</td>\n",
       "      <td>0.121431</td>\n",
       "      <td>0.127531</td>\n",
       "      <td>-0.056367</td>\n",
       "      <td>-0.088949</td>\n",
       "      <td>0.105524</td>\n",
       "      <td>-0.136770</td>\n",
       "      <td>-0.021182</td>\n",
       "      <td>0.417082</td>\n",
       "      <td>-0.055853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>-0.251642</td>\n",
       "      <td>-0.747068</td>\n",
       "      <td>0.015128</td>\n",
       "      <td>-0.648365</td>\n",
       "      <td>-0.124657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336851</td>\n",
       "      <td>-0.142544</td>\n",
       "      <td>-0.258376</td>\n",
       "      <td>-0.144581</td>\n",
       "      <td>-0.009809</td>\n",
       "      <td>-0.101721</td>\n",
       "      <td>-0.117078</td>\n",
       "      <td>-0.103890</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>-0.056691</td>\n",
       "      <td>0.285380</td>\n",
       "      <td>-0.037802</td>\n",
       "      <td>-0.111507</td>\n",
       "      <td>-0.189015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>-0.288158</td>\n",
       "      <td>-0.310891</td>\n",
       "      <td>-0.002144</td>\n",
       "      <td>-0.612246</td>\n",
       "      <td>-0.162790</td>\n",
       "      <td>0.336851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.227825</td>\n",
       "      <td>-0.125884</td>\n",
       "      <td>0.067407</td>\n",
       "      <td>-0.312154</td>\n",
       "      <td>-0.299570</td>\n",
       "      <td>0.214549</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>-0.134329</td>\n",
       "      <td>0.252617</td>\n",
       "      <td>-0.196511</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>-0.095048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>-0.126325</td>\n",
       "      <td>0.224275</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>0.060699</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>-0.142544</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013796</td>\n",
       "      <td>0.047190</td>\n",
       "      <td>-0.049888</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>-0.015061</td>\n",
       "      <td>-0.014613</td>\n",
       "      <td>-0.082027</td>\n",
       "      <td>-0.002297</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>0.077605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.510802</td>\n",
       "      <td>0.355497</td>\n",
       "      <td>0.031393</td>\n",
       "      <td>0.377848</td>\n",
       "      <td>0.077043</td>\n",
       "      <td>-0.258376</td>\n",
       "      <td>-0.227825</td>\n",
       "      <td>-0.013796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>-0.149176</td>\n",
       "      <td>0.161181</td>\n",
       "      <td>0.123853</td>\n",
       "      <td>-0.048087</td>\n",
       "      <td>-0.012854</td>\n",
       "      <td>0.128988</td>\n",
       "      <td>-0.134380</td>\n",
       "      <td>0.109694</td>\n",
       "      <td>-0.029970</td>\n",
       "      <td>0.014566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>-0.127074</td>\n",
       "      <td>0.160893</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.173238</td>\n",
       "      <td>0.156775</td>\n",
       "      <td>-0.144581</td>\n",
       "      <td>-0.125884</td>\n",
       "      <td>0.047190</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008479</td>\n",
       "      <td>0.064661</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>-0.061773</td>\n",
       "      <td>-0.120796</td>\n",
       "      <td>0.045110</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>0.098480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration_ms</th>\n",
       "      <td>-0.193440</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>-0.156123</td>\n",
       "      <td>-0.009809</td>\n",
       "      <td>0.067407</td>\n",
       "      <td>-0.049888</td>\n",
       "      <td>-0.149176</td>\n",
       "      <td>-0.008479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196236</td>\n",
       "      <td>-0.198594</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>-0.030544</td>\n",
       "      <td>0.153090</td>\n",
       "      <td>-0.153208</td>\n",
       "      <td>-0.104079</td>\n",
       "      <td>0.032853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>0.304426</td>\n",
       "      <td>0.108204</td>\n",
       "      <td>-0.001134</td>\n",
       "      <td>0.202291</td>\n",
       "      <td>0.121431</td>\n",
       "      <td>-0.101721</td>\n",
       "      <td>-0.312154</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.161181</td>\n",
       "      <td>0.064661</td>\n",
       "      <td>-0.196236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818736</td>\n",
       "      <td>-0.064828</td>\n",
       "      <td>-0.015926</td>\n",
       "      <td>0.282570</td>\n",
       "      <td>-0.416660</td>\n",
       "      <td>0.328205</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>-0.056653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popular</th>\n",
       "      <td>0.240245</td>\n",
       "      <td>0.106622</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>0.172487</td>\n",
       "      <td>0.127531</td>\n",
       "      <td>-0.117078</td>\n",
       "      <td>-0.299570</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>0.123853</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>-0.198594</td>\n",
       "      <td>0.818736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067982</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.244543</td>\n",
       "      <td>-0.395711</td>\n",
       "      <td>0.275635</td>\n",
       "      <td>0.104037</td>\n",
       "      <td>-0.027081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Electronic</th>\n",
       "      <td>0.074486</td>\n",
       "      <td>0.129381</td>\n",
       "      <td>0.024396</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>-0.056367</td>\n",
       "      <td>-0.103890</td>\n",
       "      <td>0.214549</td>\n",
       "      <td>-0.015061</td>\n",
       "      <td>-0.048087</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.056001</td>\n",
       "      <td>-0.064828</td>\n",
       "      <td>-0.067982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092309</td>\n",
       "      <td>-0.086467</td>\n",
       "      <td>-0.196084</td>\n",
       "      <td>-0.142833</td>\n",
       "      <td>-0.070610</td>\n",
       "      <td>-0.094482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Indie</th>\n",
       "      <td>-0.024333</td>\n",
       "      <td>-0.022046</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>-0.088949</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>-0.014613</td>\n",
       "      <td>-0.012854</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>-0.015926</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>-0.092309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109048</td>\n",
       "      <td>-0.247291</td>\n",
       "      <td>-0.180133</td>\n",
       "      <td>-0.089050</td>\n",
       "      <td>-0.119156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Latin</th>\n",
       "      <td>0.286851</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.168824</td>\n",
       "      <td>0.105524</td>\n",
       "      <td>-0.056691</td>\n",
       "      <td>-0.134329</td>\n",
       "      <td>-0.082027</td>\n",
       "      <td>0.128988</td>\n",
       "      <td>-0.061773</td>\n",
       "      <td>-0.030544</td>\n",
       "      <td>0.282570</td>\n",
       "      <td>0.244543</td>\n",
       "      <td>-0.086467</td>\n",
       "      <td>-0.109048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.231643</td>\n",
       "      <td>-0.168735</td>\n",
       "      <td>-0.083415</td>\n",
       "      <td>-0.111616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Other</th>\n",
       "      <td>-0.325269</td>\n",
       "      <td>-0.267266</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>-0.361038</td>\n",
       "      <td>-0.136770</td>\n",
       "      <td>0.285380</td>\n",
       "      <td>0.252617</td>\n",
       "      <td>-0.002297</td>\n",
       "      <td>-0.134380</td>\n",
       "      <td>-0.120796</td>\n",
       "      <td>0.153090</td>\n",
       "      <td>-0.416660</td>\n",
       "      <td>-0.395711</td>\n",
       "      <td>-0.196084</td>\n",
       "      <td>-0.247291</td>\n",
       "      <td>-0.231643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.382643</td>\n",
       "      <td>-0.189162</td>\n",
       "      <td>-0.253114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Pop</th>\n",
       "      <td>0.169759</td>\n",
       "      <td>0.028810</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.127179</td>\n",
       "      <td>-0.021182</td>\n",
       "      <td>-0.037802</td>\n",
       "      <td>-0.196511</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.109694</td>\n",
       "      <td>0.045110</td>\n",
       "      <td>-0.153208</td>\n",
       "      <td>0.328205</td>\n",
       "      <td>0.275635</td>\n",
       "      <td>-0.142833</td>\n",
       "      <td>-0.180133</td>\n",
       "      <td>-0.168735</td>\n",
       "      <td>-0.382643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.137790</td>\n",
       "      <td>-0.184375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Rap</th>\n",
       "      <td>0.227087</td>\n",
       "      <td>-0.021973</td>\n",
       "      <td>-0.027506</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.417082</td>\n",
       "      <td>-0.111507</td>\n",
       "      <td>-0.115875</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>-0.029970</td>\n",
       "      <td>0.076585</td>\n",
       "      <td>-0.104079</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.104037</td>\n",
       "      <td>-0.070610</td>\n",
       "      <td>-0.089050</td>\n",
       "      <td>-0.083415</td>\n",
       "      <td>-0.189162</td>\n",
       "      <td>-0.137790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_1_Rock</th>\n",
       "      <td>-0.210563</td>\n",
       "      <td>0.226736</td>\n",
       "      <td>-0.003631</td>\n",
       "      <td>0.146590</td>\n",
       "      <td>-0.055853</td>\n",
       "      <td>-0.189015</td>\n",
       "      <td>-0.095048</td>\n",
       "      <td>0.077605</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.098480</td>\n",
       "      <td>0.032853</td>\n",
       "      <td>-0.056653</td>\n",
       "      <td>-0.027081</td>\n",
       "      <td>-0.094482</td>\n",
       "      <td>-0.119156</td>\n",
       "      <td>-0.111616</td>\n",
       "      <td>-0.253114</td>\n",
       "      <td>-0.184375</td>\n",
       "      <td>-0.091147</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    danceability    energy       key  loudness  speechiness  \\\n",
       "danceability            1.000000  0.176532  0.007976  0.415339     0.235930   \n",
       "energy                  0.176532  1.000000  0.027639  0.739625     0.082852   \n",
       "key                     0.007976  0.027639  1.000000  0.023950    -0.001589   \n",
       "loudness                0.415339  0.739625  0.023950  1.000000     0.131648   \n",
       "speechiness             0.235930  0.082852 -0.001589  0.131648     1.000000   \n",
       "acousticness           -0.251642 -0.747068  0.015128 -0.648365    -0.124657   \n",
       "instrumentalness       -0.288158 -0.310891 -0.002144 -0.612246    -0.162790   \n",
       "liveness               -0.126325  0.224275 -0.025700  0.060699     0.024113   \n",
       "valence                 0.510802  0.355497  0.031393  0.377848     0.077043   \n",
       "tempo                  -0.127074  0.160893  0.014039  0.173238     0.156775   \n",
       "duration_ms            -0.193440  0.024106  0.007507  0.003117    -0.156123   \n",
       "popularity              0.304426  0.108204 -0.001134  0.202291     0.121431   \n",
       "popular                 0.240245  0.106622 -0.001273  0.172487     0.127531   \n",
       "genre_1_Electronic      0.074486  0.129381  0.024396  0.042626    -0.056367   \n",
       "genre_1_Indie          -0.024333 -0.022046  0.002311  0.000524    -0.088949   \n",
       "genre_1_Latin           0.286851  0.082822  0.003915  0.168824     0.105524   \n",
       "genre_1_Other          -0.325269 -0.267266 -0.002136 -0.361038    -0.136770   \n",
       "genre_1_Pop             0.169759  0.028810  0.002118  0.127179    -0.021182   \n",
       "genre_1_Rap             0.227087 -0.021973 -0.027506  0.055474     0.417082   \n",
       "genre_1_Rock           -0.210563  0.226736 -0.003631  0.146590    -0.055853   \n",
       "\n",
       "                    acousticness  instrumentalness  liveness   valence  \\\n",
       "danceability           -0.251642         -0.288158 -0.126325  0.510802   \n",
       "energy                 -0.747068         -0.310891  0.224275  0.355497   \n",
       "key                     0.015128         -0.002144 -0.025700  0.031393   \n",
       "loudness               -0.648365         -0.612246  0.060699  0.377848   \n",
       "speechiness            -0.124657         -0.162790  0.024113  0.077043   \n",
       "acousticness            1.000000          0.336851 -0.142544 -0.258376   \n",
       "instrumentalness        0.336851          1.000000 -0.016370 -0.227825   \n",
       "liveness               -0.142544         -0.016370  1.000000 -0.013796   \n",
       "valence                -0.258376         -0.227825 -0.013796  1.000000   \n",
       "tempo                  -0.144581         -0.125884  0.047190  0.054557   \n",
       "duration_ms            -0.009809          0.067407 -0.049888 -0.149176   \n",
       "popularity             -0.101721         -0.312154  0.007356  0.161181   \n",
       "popular                -0.117078         -0.299570  0.043259  0.123853   \n",
       "genre_1_Electronic     -0.103890          0.214549 -0.015061 -0.048087   \n",
       "genre_1_Indie           0.028512          0.012641 -0.014613 -0.012854   \n",
       "genre_1_Latin          -0.056691         -0.134329 -0.082027  0.128988   \n",
       "genre_1_Other           0.285380          0.252617 -0.002297 -0.134380   \n",
       "genre_1_Pop            -0.037802         -0.196511  0.009079  0.109694   \n",
       "genre_1_Rap            -0.111507         -0.115875  0.021431 -0.029970   \n",
       "genre_1_Rock           -0.189015         -0.095048  0.077605  0.014566   \n",
       "\n",
       "                       tempo  duration_ms  popularity   popular  \\\n",
       "danceability       -0.127074    -0.193440    0.304426  0.240245   \n",
       "energy              0.160893     0.024106    0.108204  0.106622   \n",
       "key                 0.014039     0.007507   -0.001134 -0.001273   \n",
       "loudness            0.173238     0.003117    0.202291  0.172487   \n",
       "speechiness         0.156775    -0.156123    0.121431  0.127531   \n",
       "acousticness       -0.144581    -0.009809   -0.101721 -0.117078   \n",
       "instrumentalness   -0.125884     0.067407   -0.312154 -0.299570   \n",
       "liveness            0.047190    -0.049888    0.007356  0.043259   \n",
       "valence             0.054557    -0.149176    0.161181  0.123853   \n",
       "tempo               1.000000    -0.008479    0.064661  0.062305   \n",
       "duration_ms        -0.008479     1.000000   -0.196236 -0.198594   \n",
       "popularity          0.064661    -0.196236    1.000000  0.818736   \n",
       "popular             0.062305    -0.198594    0.818736  1.000000   \n",
       "genre_1_Electronic  0.010417     0.056001   -0.064828 -0.067982   \n",
       "genre_1_Indie       0.015359     0.001493   -0.015926  0.011324   \n",
       "genre_1_Latin      -0.061773    -0.030544    0.282570  0.244543   \n",
       "genre_1_Other      -0.120796     0.153090   -0.416660 -0.395711   \n",
       "genre_1_Pop         0.045110    -0.153208    0.328205  0.275635   \n",
       "genre_1_Rap         0.076585    -0.104079    0.079321  0.104037   \n",
       "genre_1_Rock        0.098480     0.032853   -0.056653 -0.027081   \n",
       "\n",
       "                    genre_1_Electronic  genre_1_Indie  genre_1_Latin  \\\n",
       "danceability                  0.074486      -0.024333       0.286851   \n",
       "energy                        0.129381      -0.022046       0.082822   \n",
       "key                           0.024396       0.002311       0.003915   \n",
       "loudness                      0.042626       0.000524       0.168824   \n",
       "speechiness                  -0.056367      -0.088949       0.105524   \n",
       "acousticness                 -0.103890       0.028512      -0.056691   \n",
       "instrumentalness              0.214549       0.012641      -0.134329   \n",
       "liveness                     -0.015061      -0.014613      -0.082027   \n",
       "valence                      -0.048087      -0.012854       0.128988   \n",
       "tempo                         0.010417       0.015359      -0.061773   \n",
       "duration_ms                   0.056001       0.001493      -0.030544   \n",
       "popularity                   -0.064828      -0.015926       0.282570   \n",
       "popular                      -0.067982       0.011324       0.244543   \n",
       "genre_1_Electronic            1.000000      -0.092309      -0.086467   \n",
       "genre_1_Indie                -0.092309       1.000000      -0.109048   \n",
       "genre_1_Latin                -0.086467      -0.109048       1.000000   \n",
       "genre_1_Other                -0.196084      -0.247291      -0.231643   \n",
       "genre_1_Pop                  -0.142833      -0.180133      -0.168735   \n",
       "genre_1_Rap                  -0.070610      -0.089050      -0.083415   \n",
       "genre_1_Rock                 -0.094482      -0.119156      -0.111616   \n",
       "\n",
       "                    genre_1_Other  genre_1_Pop  genre_1_Rap  genre_1_Rock  \n",
       "danceability            -0.325269     0.169759     0.227087     -0.210563  \n",
       "energy                  -0.267266     0.028810    -0.021973      0.226736  \n",
       "key                     -0.002136     0.002118    -0.027506     -0.003631  \n",
       "loudness                -0.361038     0.127179     0.055474      0.146590  \n",
       "speechiness             -0.136770    -0.021182     0.417082     -0.055853  \n",
       "acousticness             0.285380    -0.037802    -0.111507     -0.189015  \n",
       "instrumentalness         0.252617    -0.196511    -0.115875     -0.095048  \n",
       "liveness                -0.002297     0.009079     0.021431      0.077605  \n",
       "valence                 -0.134380     0.109694    -0.029970      0.014566  \n",
       "tempo                   -0.120796     0.045110     0.076585      0.098480  \n",
       "duration_ms              0.153090    -0.153208    -0.104079      0.032853  \n",
       "popularity              -0.416660     0.328205     0.079321     -0.056653  \n",
       "popular                 -0.395711     0.275635     0.104037     -0.027081  \n",
       "genre_1_Electronic      -0.196084    -0.142833    -0.070610     -0.094482  \n",
       "genre_1_Indie           -0.247291    -0.180133    -0.089050     -0.119156  \n",
       "genre_1_Latin           -0.231643    -0.168735    -0.083415     -0.111616  \n",
       "genre_1_Other            1.000000    -0.382643    -0.189162     -0.253114  \n",
       "genre_1_Pop             -0.382643     1.000000    -0.137790     -0.184375  \n",
       "genre_1_Rap             -0.189162    -0.137790     1.000000     -0.091147  \n",
       "genre_1_Rock            -0.253114    -0.184375    -0.091147      1.000000  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df.corr(method='pearson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
